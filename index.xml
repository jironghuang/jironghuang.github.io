<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jirong&#39;s sandbox on Jirong&#39;s sandbox</title>
    <link>/</link>
    <description>Recent content in Jirong&#39;s sandbox on Jirong&#39;s sandbox</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Loading excel data with correct variable types</title>
      <link>/post/load_data_with_correct_types/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/load_data_with_correct_types/</guid>
      <description>Loading data with data types When reading static files into R or Python, most of the times we are lazy as we load the data with no regard to the data types.
But in mission critical ETL jobs or Data analytics workflow, data types are quintessential and there’s a fine line between life and death. Ok, I’m exaggerating here.
What I’ve written below is a swiss army knife function to read an excel file: 1st tab is data and 2nd tab is the variable types (e.</description>
    </item>
    
    <item>
      <title>Function to describe clusters derived from unsupervised learning</title>
      <link>/post/cluster_descriptive_stats/</link>
      <pubDate>Fri, 24 May 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/cluster_descriptive_stats/</guid>
      <description>Describing unsupervised learning clusters As a data scientist / analyst, besides doing cool modelling stuff, we&amp;rsquo;re often asked to churn out descriptive statistics. Yes, we know. It&amp;rsquo;s part of the process.
I chanced upon this really nifty concept at work to describe the clusters derived from unsupervised learnig. Here&amp;rsquo;s how it goes,
 Say it&amp;rsquo;s a nominal or ordinal variable. First, I find the proportion of the feature across the X clusters Second, I rank this proportion through percentiles across these X values The cluster with the highest percentile will earn its right to be represented by the feature And if it&amp;rsquo;s a scale variable, you may find the mean of the feature for each cluster and repeat the steps.</description>
    </item>
    
    <item>
      <title>Playing with Google Place API</title>
      <link>/post/google_place_api/</link>
      <pubDate>Tue, 14 May 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/google_place_api/</guid>
      <description>Google Place API I was playing around with the API to obtain lat-long for my geo analytics work.
I entered my credit card info but it seems that I&amp;rsquo;m not charged even with 9000+ API calls. Unsure if it&amp;rsquo;s because I&amp;rsquo;ve a 400+ dollars free cloud credit?
Anyway, what I did here was to make API calls and storing the data into my local database.
If you&amp;rsquo;re interested, you may visit this stackoverflow link (https://stackoverflow.</description>
    </item>
    
    <item>
      <title>Using exponential distribution to estimate frequency of occurence</title>
      <link>/post/exp_distrib/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/exp_distrib/</guid>
      <description>Simulating product failures I’m inspired by this post here (http://www.programmingr.com/examples/neat-tricks/sample-r-function/rexp/). And decided to expand on the example.
Say you are an owner of a computer store and you would like to estimate the frequency of warranty repairs - and the ensuing costs.
Here’s the scenario with the accompanying assumptions
 Each computer is expected to last an average of 7 years You only sell 1000 computers at the start of each year You sell computer from 2019 to 2025  First, I simulate an exponential distribution of 1000 points for 7 years; and place a time index of 2019 to 2025</description>
    </item>
    
    <item>
      <title>Some thoughts on Reinforcement Learning - Q Learning</title>
      <link>/post/q_learning/</link>
      <pubDate>Mon, 08 Apr 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/q_learning/</guid>
      <description>Q learning I just completed a Reinforcement Learning assignment - in particular on Q-learning. According to Wikipedia here, it&amp;rsquo;s a model-free Rl algorithm. The goal for the algo is to learn a policy, which tells an agent what action to take under different circumstances.
Here&amp;rsquo;s my confession. What I&amp;rsquo;m doing in this post is to summarise what I&amp;rsquo;ve just learnt so that I may come back to this at any point in future.</description>
    </item>
    
    <item>
      <title>What&#39;re the returns (XIRR) for my CPFIS Portfolio</title>
      <link>/project/xirr_cpf/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/xirr_cpf/</guid>
      <description>What’re the returns (XIRR) for my CPFIS Portfolio? I expounded my philosophy and calculated the returns of my CPFIS portfolio via XIRR (Extended Internal Rate of Returns) here.
The binary lens of evaluating the XIRR is as follows,
 If XIRR &amp;gt; 2.5%, my investment decision paid off Else if XIRR &amp;lt; 2.5%, my invesment decision did not pay off (not to say it’s a bad decision. Pls do not confuse decision with outcome)  As an ex-economist/ data geek who doesn’t shy away from having skin in the game, I will be honest in sharing my returns and its stream of cashflow here,</description>
    </item>
    
    <item>
      <title>What&#39;re the returns (XIRR) for my CPFIS Portfolio</title>
      <link>/post/xirr_cpfis/</link>
      <pubDate>Sat, 16 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/xirr_cpfis/</guid>
      <description>What’re the returns (XIRR) for my CPFIS Portfolio? Every employee in Singapore is bounded by the same set of CPF rules.
As an ex-economist/ data geek who doesn’t shy away from having skin in the game. I asked myself this question back in 2015 when I was still a starry-eyed young man 2 years into the workforce - how do I set out to optimize my returns in my CPF OA with these given set of constraints,</description>
    </item>
    
    <item>
      <title>Hosting a Flask App on Heroku</title>
      <link>/post/hosting-a-flask-app-on-heroku/</link>
      <pubDate>Thu, 28 Feb 2019 23:34:32 +0800</pubDate>
      
      <guid>/post/hosting-a-flask-app-on-heroku/</guid>
      <description>Following the steps here &amp;ndash;&amp;gt; https://realpython.com/flask-by-example-part-1-project-setup/
I managed to deploy my python flask app in Heroku.
from flask import Flask app = Flask(__name__) @app.route(&#39;/&#39;) def hello(): return &amp;quot;Hello World!&amp;quot; @app.route(&#39;/&amp;lt;name&amp;gt;&#39;) def hello_name(name): return &amp;quot;Hello {}!&amp;quot;.format(name) if __name__ == &#39;__main__&#39;: app.run()  You may visit the following link &amp;ndash;&amp;gt;https://jirong-stage.herokuapp.com/ &amp;amp; add a suffix to it.
Example https://jirong-stage.herokuapp.com/jirong &amp;amp; this will return Hello jirong!
Possibilites are immense! I can easily create APIs or host dashboard here.</description>
    </item>
    
    <item>
      <title>Sampling With Replacement Through First Principles</title>
      <link>/post/sampling-with-replacement-through-first-principles/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/sampling-with-replacement-through-first-principles/</guid>
      <description>Sampling with replacement Hello! It&amp;rsquo;s me once again attempting to explain things from first principles - a term popularized by Elon Musk.
I will use some psudeo code - on sampling with replacement for weights - to aid my explanation.
Earlier in the week, I attempted to write a simple function from scratch but I gave up after realising that it will take me more than 15 mins! Difficulties lies in the multiple switch statements in defining the intervals.</description>
    </item>
    
    <item>
      <title>Building a decision tree algorithm from scratch</title>
      <link>/post/building-adecision-tree-from-scratch/</link>
      <pubDate>Fri, 15 Feb 2019 13:09:44 +0800</pubDate>
      
      <guid>/post/building-adecision-tree-from-scratch/</guid>
      <description>Building a decision tree from scratch Sometimes to truly understand and internalise an algorithm, it&amp;rsquo;s always useful to build from scratch. Rather than relying on a module or library written by someone else.
I&amp;rsquo;m fortunate to be given the chance to do it in 1 of my assignments for decision trees.
From this exercise, I had to rely on my knowledge on recursion, binary trees (in-order traversal) and object oriented programming.</description>
    </item>
    
    <item>
      <title>Martingale Strategy - Double Down</title>
      <link>/post/martingale-strategy/</link>
      <pubDate>Sat, 26 Jan 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/martingale-strategy/</guid>
      <description>Martingale Strategy In this post, I will simulate a martingale strategy in Roulette&amp;rsquo;s context to highlight the potential risks associated with this strategy.
Double down! That&amp;rsquo;s essentially the essence of it.
Here&amp;rsquo;s a simple explanation of the strategy,
 The croupier spins the ball. If it&amp;rsquo;s red you win the amount you bet, black you lose the same amount If you win, you continue to bet the same amount (same as your 1st bet amount) If you lose, you double your bet amount And if your accumulated winnings hits a certain amount, you stop and leave the casino  So how would the strategy fare?</description>
    </item>
    
    <item>
      <title>How to Create a Python Environment in Ubuntu or any Debian-based system</title>
      <link>/post/how-to-create-a-python-environment-in-ubuntu/</link>
      <pubDate>Wed, 09 Jan 2019 23:39:22 +0800</pubDate>
      
      <guid>/post/how-to-create-a-python-environment-in-ubuntu/</guid>
      <description>Often, certain projects or classes involving python require a set of modules/packages for the code to work.
1 solution is to create a Python Environment dedicated to that project.
First set up a folder, and include a .yml file with the specific modules and environment that you wish to install. Here is an example (env.yml),
name: env channels: !!python/tuple - !!python/unicode &#39;defaults&#39; dependencies: - nb_conda=2.2.0=py27_0 - python=2.7.13=0 - cycler=0.10.0 - functools32=3.</description>
    </item>
    
    <item>
      <title>Translating Ernest Chan Kalman Filter Strategy Matlab and Python Code Into R</title>
      <link>/post/translating-ernest-chan-kalman-filter-strategy-matlab-and-python-code-into-r/</link>
      <pubDate>Tue, 01 Jan 2019 00:15:53 +0800</pubDate>
      
      <guid>/post/translating-ernest-chan-kalman-filter-strategy-matlab-and-python-code-into-r/</guid>
      <description>Translating Ernest Chan Kalman Filter Strategy Matlab and Python Code Into R I&amp;rsquo;m really intrigued by Ernest Chan&amp;rsquo;s approach in Quant Trading.
Often in the retail trading space, what &amp;lsquo;gurus&amp;rsquo; preach often sounds really dubious. But Ernest Chan is different. He&amp;rsquo;s sincere, down-to-earth and earnest (meant to be a pun here).
In my first month of deploying algo trading strategies, I focus mainly on mean-reversion strategies - paricularly amongst pairs.</description>
    </item>
    
    <item>
      <title>How I Find Country Pairs for Mean Reversion Strategy</title>
      <link>/post/how-i-find-country-pairs-for-mean-reversion-strategy/</link>
      <pubDate>Wed, 26 Dec 2018 12:30:03 +0800</pubDate>
      
      <guid>/post/how-i-find-country-pairs-for-mean-reversion-strategy/</guid>
      <description>How I Find Country Pairs for Mean Reversion Strategy As mentioned in my previous post here, the first step for a mean reversion strategy is to conduct some background quantitative research.
Step 1 First, I use a pair trading function to loop across 800+ country pairs (created from combination function),
pair_trading = function(stock1, stock2, trade_amount, finance_rates, start_date, end_date, prop_train, enter_z_score, exit_z_score){ ## More codes here ## Return this key_info = list( ticker = c(stock1, stock2), start_date = start_date, trade_table = data_trade, sharpe = c(sharpeRatioTrainset, sharpeRatioTestset), half_life = half_life, profits = data_trade_stats, max_drawdown = c(table.</description>
    </item>
    
    <item>
      <title>Research to Production Pipeline for Mean Reversion</title>
      <link>/post/research-to-production-pipeline-for-mean-reversion/</link>
      <pubDate>Tue, 25 Dec 2018 18:07:19 +0800</pubDate>
      
      <guid>/post/research-to-production-pipeline-for-mean-reversion/</guid>
      <description>Research to Production Pipeline for Mean Reversion Here is a high level overview of something that I&amp;rsquo;m working on.
I&amp;rsquo;ve been grappling with the finite state automata Event Driven Computing transitions and I kinda sorted it out for production use.</description>
    </item>
    
  </channel>
</rss>
