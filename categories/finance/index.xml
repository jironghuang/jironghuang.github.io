<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>finance on Jirong&#39;s sandbox</title>
    <link>/jironghuang.github.io/categories/finance/</link>
    <description>Recent content in finance on Jirong&#39;s sandbox</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Mon, 23 Sep 2019 00:00:00 +0000</lastBuildDate>
    <atom:link href="/jironghuang.github.io/categories/finance/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Market Neutral Strategy - DAX Index and EWG ETF</title>
      <link>/jironghuang.github.io/post/market_neutral_ewg/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/jironghuang.github.io/post/market_neutral_ewg/</guid>
      <description>


&lt;div id=&#34;dax-index-and-germany-etf&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;DAX index and Germany ETF&lt;/h2&gt;
&lt;p&gt;I will keep it short in this post since I espoused on this strategy a couple of times.&lt;/p&gt;
&lt;p&gt;I discovered another market neutral opportunity this month.&lt;/p&gt;
&lt;p&gt;And this is based on ratio between Germany DAX index and MSCI based Germany ETF (EWG)&lt;/p&gt;
&lt;p&gt;Based on backtest, sharpe ratio is close to 1.16.&lt;/p&gt;
&lt;p&gt;The composition between these 2 indexes are largely similar and any significant deviation shouldn’t persist for long.&lt;/p&gt;
&lt;p&gt;The optimal lookback period for the MA component in bollinger band is approximately 30 days.&lt;/p&gt;
&lt;p&gt;As this is backed by stellar performance and economic reason, I’ve decided to deploy some capital to this strategy.&lt;/p&gt;
&lt;div id=&#34;disclosure&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Disclosure&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;I executed a short (DAX 30) CFD long (EWG) strategy on 23-September with approximately $35880 on both positions.&lt;/li&gt;
&lt;li&gt;I entered at a ratio of 12345/26.97 = 457.7308 with expected profits of 1.04%.&lt;/li&gt;
&lt;li&gt;Max holding period is 16 work days (ending on 15th October 2019) based on half life formula here (&lt;a href=&#34;http://en.wikipedia.org/wiki/Ornstein-Uhlenbeck_process&#34; class=&#34;uri&#34;&gt;http://en.wikipedia.org/wiki/Ornstein-Uhlenbeck_process&lt;/a&gt;) as advised by Ernest Chan. See his example for further explanation&lt;/li&gt;
&lt;li&gt;I’m using pushoverr notification api linked to my phone app within my cron task scheduler. It will inform me to close my positions when the ratio dips below moving average.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressMessages(sapply(c(&amp;quot;zoo&amp;quot;, &amp;quot;tidyr&amp;quot;, &amp;quot;plyr&amp;quot;, &amp;quot;dplyr&amp;quot;,
         &amp;quot;gtools&amp;quot;,&amp;quot;googlesheets&amp;quot;, &amp;quot;quantmod&amp;quot;, 
         &amp;quot;urca&amp;quot;, &amp;quot;PerformanceAnalytics&amp;quot;, &amp;quot;parallel&amp;quot;, &amp;quot;TTR&amp;quot;, &amp;quot;pushoverr&amp;quot;), require, character.only = T))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  zoo                tidyr                 plyr 
##                 TRUE                 TRUE                 TRUE 
##                dplyr               gtools         googlesheets 
##                 TRUE                 TRUE                 TRUE 
##             quantmod                 urca PerformanceAnalytics 
##                 TRUE                 TRUE                 TRUE 
##             parallel                  TTR            pushoverr 
##                 TRUE                 TRUE                 TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;#39;util/calculateReturns.R&amp;#39;)
source(&amp;#39;util/calculateMaxDD.R&amp;#39;)
source(&amp;#39;util/backshift.R&amp;#39;)
source(&amp;#39;util/extract_stock_prices.R&amp;#39;)
source(&amp;#39;util/cointegration_pair.R&amp;#39;)

stock1 = &amp;quot;^GDAXI&amp;quot;
stock2 = &amp;quot;EWG&amp;quot;

n_days = 30

prop_train = 0.7

start_date = &amp;quot;2000-07-01&amp;quot;
end_date = &amp;quot;2019-12-30&amp;quot;

#Start of function
data1 = df_crawl_time_series(stock1, start_date, end_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;getSymbols&amp;#39; currently uses auto.assign=TRUE by default, but will
## use auto.assign=FALSE in 0.5-0. You will still be able to use
## &amp;#39;loadSymbols&amp;#39; to automatically load data. getOption(&amp;quot;getSymbols.env&amp;quot;)
## and getOption(&amp;quot;getSymbols.auto.assign&amp;quot;) will still be checked for
## alternate defaults.
## 
## This message is shown once per session and may be disabled by setting 
## options(&amp;quot;getSymbols.warning4.0&amp;quot;=FALSE). See ?getSymbols for details.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## WARNING: There have been significant changes to Yahoo Finance data.
## Please see the Warning section of &amp;#39;?getSymbols.yahoo&amp;#39; for details.
## 
## This message is shown once per session and may be disabled by setting
## options(&amp;quot;getSymbols.yahoo.warning&amp;quot;=FALSE).&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: ^GDAXI contains missing values. Some functions will not work if
## objects contain missing values in the middle of the series. Consider using
## na.omit(), na.approx(), na.fill(), etc to remove or replace them.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data1 = subset(data1, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Adj.Close&amp;quot;))
names(data1) = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Close&amp;quot;)
data1$Date = as.Date(data1$Date)

data2 = df_crawl_time_series(stock2, start_date, end_date)
data2 = subset(data2, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Adj.Close&amp;quot;))
names(data2) = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Close&amp;quot;)
data2$Date = as.Date(data2$Date)

#Training and testing index
data1 = xts(data1[, -1], order.by = data1[, 1])
data2 = xts(data2[, -1], order.by = data2[, 1])

data = merge(data1, data2)
data = as.data.frame(data)
data = subset(data, !is.na(data$Close) &amp;amp; !is.na(data$Close.1))

data$ratio = data$Close/ data$Close.1

# plot(data$ratio)
bb_ratio = data.frame(BBands(data$ratio,n = n_days))
data = cbind(data, bb_ratio)
data_sub = tail(data, 1000)

plot(data_sub$ratio)
lines(data_sub$mavg, col = &amp;quot;red&amp;quot;)
lines(data_sub$up, col = &amp;quot;blue&amp;quot;)
lines(data_sub$dn, col = &amp;quot;green&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/jironghuang.github.io/post/market_neutral_ewg_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#If lower than 
data_sub$longs &amp;lt;- data_sub$ratio &amp;lt;= data_sub$dn # buy spread when its value drops below 2 standard deviations.
data_sub$shorts &amp;lt;- data_sub$ratio &amp;gt;= data_sub$up # short spread when its value rises above 2 standard deviations.

#  exit any spread position when its value is at moving average
data_sub$longExits   &amp;lt;- data_sub$ratio &amp;gt;= data_sub$mavg
data_sub$shortExits &amp;lt;- data_sub$ratio &amp;lt;= data_sub$mavg


# #  define indices for training and test sets
# trainset &amp;lt;- 1:as.integer(nrow(data) * prop_train)
# testset &amp;lt;- (length(trainset)+1):nrow(data)

#Signal
data_sub$posL1 = NA
data_sub$posL2 = NA
data_sub$posS1 = NA
data_sub$posS2 = NA

# initialize to 0
data_sub$posL1[1] &amp;lt;- 0; data_sub$posL2[1] &amp;lt;- 0
data_sub$posS1[1] &amp;lt;- 0; data_sub$posS2[1] &amp;lt;- 0

data_sub$posL1[data_sub$longs] &amp;lt;- 1
data_sub$posL2[data_sub$longs] &amp;lt;- -1

data_sub$posS1[data_sub$shorts] &amp;lt;- -1
data_sub$posS2[data_sub$shorts] &amp;lt;- 1

data_sub$posL1[data_sub$longExits] &amp;lt;- 0
data_sub$posL2[data_sub$longExits] &amp;lt;- 0
data_sub$posS1[data_sub$shortExits] &amp;lt;- 0
data_sub$posS2[data_sub$shortExits] &amp;lt;- 0

#positions
data_sub$posL1 &amp;lt;- zoo::na.locf(data_sub$posL1); data_sub$posL2 &amp;lt;- zoo::na.locf(data_sub$posL2)
data_sub$posS1 &amp;lt;- zoo::na.locf(data_sub$posS1); data_sub$posS2 &amp;lt;- zoo::na.locf(data_sub$posS2)
data_sub$position1 &amp;lt;- data_sub$posL1 + data_sub$posS1
data_sub$position2 &amp;lt;- data_sub$posL2 + data_sub$posS2

#Returns
data_sub$dailyret1 &amp;lt;- ROC(data_sub$Close) #  last row is [385,] -0.0122636689 -0.0140365802
data_sub$dailyret2 &amp;lt;- ROC(data_sub$Close.1) #  last row is [385,] -0.0122636689 -0.0140365802

#Backshifting here. But signal is for following day returns!. So can still use latest Z-score
data_sub$date = as.Date(row.names(data_sub))
data_sub = xts(data_sub[,-which(names(data_sub) == &amp;quot;date&amp;quot;)], order.by = data_sub[, which(names(data_sub) == &amp;quot;date&amp;quot;)])

#Doesn&amp;#39;t account for number of shares!!!!!
data_sub$pnl = lag(data_sub$position1, 1) * data_sub$dailyret1  + lag(data_sub$position2, 1) * data_sub$dailyret2

#Performance analytics
tryCatch({
  charts.PerformanceSummary(data_sub$pnl)
}, error = function(e){})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/jironghuang.github.io/post/market_neutral_ewg_files/figure-html/unnamed-chunk-1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table.Drawdowns(data_sub$pnl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         From     Trough         To   Depth Length To Trough Recovery
## 1 2017-05-11 2017-08-02 2018-01-09 -0.0622    164        57      107
## 2 2018-04-26 2018-05-29 2018-08-17 -0.0559     78        21       57
## 3 2015-10-26 2015-11-30 2015-12-17 -0.0504     38        25       13
## 4 2018-01-11 2018-02-01 2018-02-07 -0.0431     19        15        4
## 5 2016-12-08 2016-12-19 2017-03-10 -0.0425     63         8       55&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table.DownsideRisk(data_sub$pnl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                   pnl
## Semi Deviation                 0.0030
## Gain Deviation                 0.0057
## Loss Deviation                 0.0041
## Downside Deviation (MAR=210%)  0.0091
## Downside Deviation (Rf=0%)     0.0029
## Downside Deviation (0%)        0.0029
## Maximum Drawdown               0.0622
## Historical VaR (95%)          -0.0069
## Historical ES (95%)           -0.0104
## Modified VaR (95%)            -0.0043
## Modified ES (95%)             -0.0043&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table.AnnualizedReturns(data_sub$pnl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                              pnl
## Annualized Return         0.0898
## Annualized Std Dev        0.0773
## Annualized Sharpe (Rf=0%) 1.1617&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Extract the moving average, ratio
update = paste(stock1, stock2,
               &amp;quot;Current ratio is:&amp;quot;, round(as.numeric(data_sub$ratio[nrow(data_sub)]), 3), 
               &amp;quot;Moving average is&amp;quot;, round(as.numeric(data_sub$mavg[nrow(data_sub)]), 3),
               &amp;quot;Expected profits left in %&amp;quot;, abs(round(100 * (as.numeric(data_sub$ratio[nrow(data_sub)]) - as.numeric(data_sub$mavg[nrow(data_sub)]))/as.numeric(data_sub$ratio[nrow(data_sub)]), 1)),
               &amp;quot;UB is&amp;quot;, round(as.numeric(data_sub$up[nrow(data_sub)]), 3),
               &amp;quot;LB is&amp;quot;, round(as.numeric(data_sub$dn[nrow(data_sub)]), 3)               
)

if(as.numeric(data_sub$ratio[nrow(data_sub)]) &amp;lt; as.numeric(data_sub$dn[nrow(data_sub)])) {
  update = paste(update, &amp;quot;Long ratio!&amp;quot;)
} else{
  update = paste(update, &amp;quot;\nDon&amp;#39;t enter\n&amp;quot;)
}

if(as.numeric(data_sub$ratio[nrow(data_sub)]) &amp;gt; as.numeric(data_sub$up[nrow(data_sub)])) {
  update = paste(update, &amp;quot;Short ratio!&amp;quot;)
} else{
  update = paste(update, &amp;quot;Don&amp;#39;t enter&amp;quot;)
}

# if(as.numeric(data_sub$ratio[nrow(data_sub)]) &amp;lt; as.numeric(data_sub$mavg[nrow(data_sub)])) {
#   update = paste(update, &amp;quot;Liquidate position!&amp;quot;)
# } else{
#   update = paste(update, &amp;quot;Hold&amp;quot;)
# }

#pushover(message = update, user = Sys.getenv(&amp;quot;pushover_user&amp;quot;), app = Sys.getenv(&amp;quot;pushover_app&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Market Neutral Strategy - FTSE Index and EWU ETF</title>
      <link>/jironghuang.github.io/post/market_neutral_ewu/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/jironghuang.github.io/post/market_neutral_ewu/</guid>
      <description>


&lt;div id=&#34;uk-index-and-uk-etf&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;UK index and UK ETF&lt;/h2&gt;
&lt;p&gt;I discovered another market neutral opportunity this month.&lt;/p&gt;
&lt;p&gt;And this is based on ratio between FTSE 100 index and MSCI based UK ETF (EWU)&lt;/p&gt;
&lt;p&gt;Based on backtest, sharpe ratio is close to 0.9.&lt;/p&gt;
&lt;p&gt;The composition between these 2 indexes are largely similar and any significant deviation shouldn’t persist for long.&lt;/p&gt;
&lt;p&gt;The optimal lookback period for the MA component in bollinger band is approximately 40 days.&lt;/p&gt;
&lt;p&gt;As this is backed by stellar performance and economic reason, I’ve decided to deploy some capital to this strategy.&lt;/p&gt;
&lt;div id=&#34;disclosure&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Disclosure&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;I executed a long (FTSE 100) CFD short (EWU) strategy on 18-September with approximately $25000 on both positions. Equity to loan (with no cash) outlay is only 3750 dollars on long side. I entered at a ratio of 232 with expected profits of 2.4% excluding further 2% p.a. of interest on short sale cash. I expect a 3% long finance rate of approximately 2 dollars per day. Short interest gain rate is around 1.5% translating to 1 dollars per day. Net finance cost is around 1 dollar a day.&lt;/li&gt;
&lt;li&gt;Max holding period is 24 work days (ending on 22nd October 2019) based on half life formula here (&lt;a href=&#34;http://en.wikipedia.org/wiki/Ornstein-Uhlenbeck_process&#34; class=&#34;uri&#34;&gt;http://en.wikipedia.org/wiki/Ornstein-Uhlenbeck_process&lt;/a&gt;) as advised by Ernest Chan. See his example for further explanation&lt;/li&gt;
&lt;li&gt;I’m using pushoverr notification api linked to my phone app within my cron task scheduler. It will inform me to close my positions when the ratio dips below moving average.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressMessages(sapply(c(&amp;quot;zoo&amp;quot;, &amp;quot;tidyr&amp;quot;, &amp;quot;plyr&amp;quot;, &amp;quot;dplyr&amp;quot;,
         &amp;quot;gtools&amp;quot;,&amp;quot;googlesheets&amp;quot;, &amp;quot;quantmod&amp;quot;, 
         &amp;quot;urca&amp;quot;, &amp;quot;PerformanceAnalytics&amp;quot;, &amp;quot;parallel&amp;quot;, &amp;quot;TTR&amp;quot;, &amp;quot;pushoverr&amp;quot;), require, character.only = T))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  zoo                tidyr                 plyr 
##                 TRUE                 TRUE                 TRUE 
##                dplyr               gtools         googlesheets 
##                 TRUE                 TRUE                 TRUE 
##             quantmod                 urca PerformanceAnalytics 
##                 TRUE                 TRUE                 TRUE 
##             parallel                  TTR            pushoverr 
##                 TRUE                 TRUE                 TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;#39;util/calculateReturns.R&amp;#39;)
source(&amp;#39;util/calculateMaxDD.R&amp;#39;)
source(&amp;#39;util/backshift.R&amp;#39;)
source(&amp;#39;util/extract_stock_prices.R&amp;#39;)
source(&amp;#39;util/cointegration_pair.R&amp;#39;)

stock1 = &amp;quot;^FTSE&amp;quot;
stock2 = &amp;quot;EWU&amp;quot;

n_days = 40

prop_train = 0.7

start_date = &amp;quot;2000-07-01&amp;quot;
end_date = &amp;quot;2019-12-30&amp;quot;

#Start of function
data1 = df_crawl_time_series(stock1, start_date, end_date)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;getSymbols&amp;#39; currently uses auto.assign=TRUE by default, but will
## use auto.assign=FALSE in 0.5-0. You will still be able to use
## &amp;#39;loadSymbols&amp;#39; to automatically load data. getOption(&amp;quot;getSymbols.env&amp;quot;)
## and getOption(&amp;quot;getSymbols.auto.assign&amp;quot;) will still be checked for
## alternate defaults.
## 
## This message is shown once per session and may be disabled by setting 
## options(&amp;quot;getSymbols.warning4.0&amp;quot;=FALSE). See ?getSymbols for details.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## WARNING: There have been significant changes to Yahoo Finance data.
## Please see the Warning section of &amp;#39;?getSymbols.yahoo&amp;#39; for details.
## 
## This message is shown once per session and may be disabled by setting
## options(&amp;quot;getSymbols.yahoo.warning&amp;quot;=FALSE).&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: ^FTSE contains missing values. Some functions will not work if
## objects contain missing values in the middle of the series. Consider using
## na.omit(), na.approx(), na.fill(), etc to remove or replace them.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data1 = subset(data1, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Adj.Close&amp;quot;))
names(data1) = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Close&amp;quot;)
data1$Date = as.Date(data1$Date)

data2 = df_crawl_time_series(stock2, start_date, end_date)
data2 = subset(data2, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Adj.Close&amp;quot;))
names(data2) = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Close&amp;quot;)
data2$Date = as.Date(data2$Date)

#Training and testing index
data1 = xts(data1[, -1], order.by = data1[, 1])
data2 = xts(data2[, -1], order.by = data2[, 1])

data = merge(data1, data2)
data = as.data.frame(data)
data = subset(data, !is.na(data$Close) &amp;amp; !is.na(data$Close.1))

data$ratio = data$Close/ data$Close.1

# plot(data$ratio)
bb_ratio = data.frame(BBands(data$ratio,n = n_days))
data = cbind(data, bb_ratio)
data_sub = tail(data, 1000)

plot(data_sub$ratio)
lines(data_sub$mavg, col = &amp;quot;red&amp;quot;)
lines(data_sub$up, col = &amp;quot;blue&amp;quot;)
lines(data_sub$dn, col = &amp;quot;green&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/jironghuang.github.io/post/market_neutral_ewu_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#If lower than 
data_sub$longs &amp;lt;- data_sub$ratio &amp;lt;= data_sub$dn # buy spread when its value drops below 2 standard deviations.
data_sub$shorts &amp;lt;- data_sub$ratio &amp;gt;= data_sub$up # short spread when its value rises above 2 standard deviations.

#  exit any spread position when its value is at moving average
data_sub$longExits   &amp;lt;- data_sub$ratio &amp;gt;= data_sub$mavg
data_sub$shortExits &amp;lt;- data_sub$ratio &amp;lt;= data_sub$mavg


# #  define indices for training and test sets
# trainset &amp;lt;- 1:as.integer(nrow(data) * prop_train)
# testset &amp;lt;- (length(trainset)+1):nrow(data)

#Signal
data_sub$posL1 = NA
data_sub$posL2 = NA
data_sub$posS1 = NA
data_sub$posS2 = NA

# initialize to 0
data_sub$posL1[1] &amp;lt;- 0; data_sub$posL2[1] &amp;lt;- 0
data_sub$posS1[1] &amp;lt;- 0; data_sub$posS2[1] &amp;lt;- 0

data_sub$posL1[data_sub$longs] &amp;lt;- 1
data_sub$posL2[data_sub$longs] &amp;lt;- -1

data_sub$posS1[data_sub$shorts] &amp;lt;- -1
data_sub$posS2[data_sub$shorts] &amp;lt;- 1

data_sub$posL1[data_sub$longExits] &amp;lt;- 0
data_sub$posL2[data_sub$longExits] &amp;lt;- 0
data_sub$posS1[data_sub$shortExits] &amp;lt;- 0
data_sub$posS2[data_sub$shortExits] &amp;lt;- 0

#positions
data_sub$posL1 &amp;lt;- zoo::na.locf(data_sub$posL1); data_sub$posL2 &amp;lt;- zoo::na.locf(data_sub$posL2)
data_sub$posS1 &amp;lt;- zoo::na.locf(data_sub$posS1); data_sub$posS2 &amp;lt;- zoo::na.locf(data_sub$posS2)
data_sub$position1 &amp;lt;- data_sub$posL1 + data_sub$posS1
data_sub$position2 &amp;lt;- data_sub$posL2 + data_sub$posS2

#Returns
data_sub$dailyret1 &amp;lt;- ROC(data_sub$Close) #  last row is [385,] -0.0122636689 -0.0140365802
data_sub$dailyret2 &amp;lt;- ROC(data_sub$Close.1) #  last row is [385,] -0.0122636689 -0.0140365802

#Backshifting here. But signal is for following day returns!. So can still use latest Z-score
data_sub$date = as.Date(row.names(data_sub))
data_sub = xts(data_sub[,-which(names(data_sub) == &amp;quot;date&amp;quot;)], order.by = data_sub[, which(names(data_sub) == &amp;quot;date&amp;quot;)])

#Doesn&amp;#39;t account for number of shares!!!!!
data_sub$pnl = lag(data_sub$position1, 1) * data_sub$dailyret1  + lag(data_sub$position2, 1) * data_sub$dailyret2

#Performance analytics
tryCatch({
  charts.PerformanceSummary(data_sub$pnl)
}, error = function(e){})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/jironghuang.github.io/post/market_neutral_ewu_files/figure-html/unnamed-chunk-1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table.Drawdowns(data_sub$pnl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         From     Trough         To   Depth Length To Trough Recovery
## 1 2017-12-13 2018-02-01 2018-03-27 -0.0703     70        33       37
## 2 2015-12-18 2016-01-27 2016-03-03 -0.0626     50        25       25
## 3 2016-10-06 2016-10-28 2016-12-15 -0.0509     50        17       33
## 4 2016-06-29 2016-07-07 2016-10-05 -0.0471     68         6       62
## 5 2019-07-15 2019-08-01       &amp;lt;NA&amp;gt; -0.0442     50        14       NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table.DownsideRisk(data_sub$pnl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                   pnl
## Semi Deviation                 0.0035
## Gain Deviation                 0.0057
## Loss Deviation                 0.0045
## Downside Deviation (MAR=210%)  0.0095
## Downside Deviation (Rf=0%)     0.0034
## Downside Deviation (0%)        0.0034
## Maximum Drawdown               0.0703
## Historical VaR (95%)          -0.0083
## Historical ES (95%)           -0.0125
## Modified VaR (95%)            -0.0065
## Modified ES (95%)             -0.0065&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table.AnnualizedReturns(data_sub$pnl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                              pnl
## Annualized Return         0.0748
## Annualized Std Dev        0.0867
## Annualized Sharpe (Rf=0%) 0.8630&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Extract the moving average, ratio
update = paste(stock1, stock2,
               &amp;quot;Current ratio is:&amp;quot;, round(as.numeric(data_sub$ratio[nrow(data_sub)]), 3), 
               &amp;quot;Moving average is&amp;quot;, round(as.numeric(data_sub$mavg[nrow(data_sub)]), 3),
               &amp;quot;Expected profits left in %&amp;quot;, abs(round(100 * (as.numeric(data_sub$ratio[nrow(data_sub)]) - as.numeric(data_sub$mavg[nrow(data_sub)]))/as.numeric(data_sub$ratio[nrow(data_sub)]), 1)),
               &amp;quot;UB is&amp;quot;, round(as.numeric(data_sub$up[nrow(data_sub)]), 3),
               &amp;quot;LB is&amp;quot;, round(as.numeric(data_sub$dn[nrow(data_sub)]), 3)               
)

if(as.numeric(data_sub$ratio[nrow(data_sub)]) &amp;lt; as.numeric(data_sub$dn[nrow(data_sub)])) {
  update = paste(update, &amp;quot;Long ratio!&amp;quot;)
} else{
  update = paste(update, &amp;quot;\nDon&amp;#39;t enter\n&amp;quot;)
}

if(as.numeric(data_sub$ratio[nrow(data_sub)]) &amp;gt; as.numeric(data_sub$up[nrow(data_sub)])) {
  update = paste(update, &amp;quot;Short ratio!&amp;quot;)
} else{
  update = paste(update, &amp;quot;Don&amp;#39;t enter&amp;quot;)
}

# if(as.numeric(data_sub$ratio[nrow(data_sub)]) &amp;lt; as.numeric(data_sub$mavg[nrow(data_sub)])) {
#   update = paste(update, &amp;quot;Liquidate position!&amp;quot;)
# } else{
#   update = paste(update, &amp;quot;Hold&amp;quot;)
# }

#pushover(message = update, user = Sys.getenv(&amp;quot;pushover_user&amp;quot;), app = Sys.getenv(&amp;quot;pushover_app&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Market Neutral Strategy - SnP500 (SPY) to Berkshire Hathaway Ratio</title>
      <link>/jironghuang.github.io/post/market_neutral/</link>
      <pubDate>Sat, 24 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/jironghuang.github.io/post/market_neutral/</guid>
      <description>


&lt;div id=&#34;market-neutral-strategy&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Market neutral strategy&lt;/h2&gt;
&lt;p&gt;As the negative news pile up (trade wars, slump in economy growths, etc), I sought for market neutral stategies that could perform well in any market environment.&lt;/p&gt;
&lt;p&gt;An idea that struck me recently is to exploit the pair between Berkshire and SnP 500 ETF.&lt;/p&gt;
&lt;p&gt;The SnP500 ETF/ Berkshire ratio has been falling over the years - insinuating that Berkshire still outperforms the index in the last couple of years.&lt;/p&gt;
&lt;p&gt;And what’s more impressive, it’s still widely regarded as a safe haven in times of trouble.&lt;/p&gt;
&lt;div id=&#34;strategy&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Strategy&lt;/h3&gt;
&lt;p&gt;As the market is facing headwind and I sought for a market neutral strategy.&lt;/p&gt;
&lt;p&gt;Here’s what I did,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I derive the SnP500 ETF/ Berkshire ratio over last 5 years&lt;/li&gt;
&lt;li&gt;And I fix a Bollinger Band around the ratio with n = 200 days as the moving average parameter - with 2 SD as the lower (lb) and upper bound (ub) line. Bollinger band ratio accounts for the downward trend in the ratio over time.&lt;/li&gt;
&lt;li&gt;If the ratio is below the lb, I will long SnP500 and short Berkshire Hathaway. And when it mean reverts and touches the middle moving average, I will exit the positions&lt;/li&gt;
&lt;li&gt;Conversely if the ratio is above the ub, I will short SnP500 and long Berkshire Hathaway. Similarly, I will exit the position when it touches the moving average&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;So how did the strategy fare? Fairly impressive I must say.&lt;/p&gt;
&lt;p&gt;Sharpe ratio is around 0.65. Annualized return is around 4.5% with the positions only in the market 30% of the time!&lt;/p&gt;
&lt;p&gt;That being said, I’m cherry picking here because the performance before this period is sub-par; probably because of a change in market regime. You may execute my code to stress-test this simple strategy.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;disclosure&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Disclosure&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;I executed a long (BRK-B) short (SPY) strategy on 26-August with approximately $11500 on both positions. Cash outlay is only 11500 dollars on long side. I’m also earning further 2% interest on cash received from short sale held as collateral. I entered at a ratio of 1.439 with expected profits of 5-6% excluding further 2% p.a. of interest on short sale cash.&lt;/li&gt;
&lt;li&gt;Max holding period is 27 work days based on half life formula here (&lt;a href=&#34;http://en.wikipedia.org/wiki/Ornstein-Uhlenbeck_process&#34; class=&#34;uri&#34;&gt;http://en.wikipedia.org/wiki/Ornstein-Uhlenbeck_process&lt;/a&gt;) as advised by Ernest Chan. See his example for further explanation&lt;/li&gt;
&lt;li&gt;I’m using pushoverr notification api linked to my phone app within my cron task scheduler. It will inform me to close my positions when the ratio dips below moving average.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;running-packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Running packages&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;##                  zoo                tidyr                 plyr 
##                 TRUE                 TRUE                 TRUE 
##                dplyr               gtools         googlesheets 
##                 TRUE                 TRUE                 TRUE 
##             quantmod                 urca PerformanceAnalytics 
##                 TRUE                 TRUE                 TRUE 
##             parallel                  TTR 
##                 TRUE                 TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Function&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Function using bollinger band
lf_bollinger_pair_trading = function(stock1, stock2, start_date, end_date, prop_res, bband_days){
  
#Start of function
data1 = df_crawl_time_series(stock1, start_date, end_date)
data1 = base::subset(data1, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Adj.Close&amp;quot;))
names(data1) = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Close&amp;quot;)
data1$Date = as.Date(data1$Date)

data2 = df_crawl_time_series(stock2, start_date, end_date)
data2 = base::subset(data2, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Adj.Close&amp;quot;))
names(data2) = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Close&amp;quot;)
data2$Date = as.Date(data2$Date)

#Training and testing index
data1 = xts(data1[, -1], order.by = data1[, 1])
data2 = xts(data2[, -1], order.by = data2[, 1])

data = merge(data1, data2)
data = as.data.frame(data)
data = subset(data, !is.na(data$Close) &amp;amp; !is.na(data$Close.1))

data$ratio = data$Close/ data$Close.1

# plot(data$ratio)
bb_ratio = data.frame(BBands( data$ratio, n = bband_days))
data = cbind(data, bb_ratio)
data_sub = tail(data, round(nrow(data) * prop_res, 0))

plot(data_sub$ratio)
lines(data_sub$mavg, col = &amp;quot;red&amp;quot;)
lines(data_sub$up, col = &amp;quot;blue&amp;quot;)
lines(data_sub$dn, col = &amp;quot;green&amp;quot;)

#If lower than 
data_sub$longs &amp;lt;- data_sub$ratio &amp;lt;= data_sub$dn # buy spread when its value drops below 2 standard deviations.
data_sub$shorts &amp;lt;- data_sub$ratio &amp;gt;= data_sub$up # short spread when its value rises above 2 standard deviations.

#  exit any spread position when its value is at moving average
data_sub$longExits   &amp;lt;- data_sub$ratio &amp;gt;= data_sub$mavg
data_sub$shortExits &amp;lt;- data_sub$ratio &amp;lt;= data_sub$mavg


# #  define indices for training and test sets
# trainset &amp;lt;- 1:as.integer(nrow(data) * prop_train)
# testset &amp;lt;- (length(trainset)+1):nrow(data)

#Signal
data_sub$posL1 = NA
data_sub$posL2 = NA
data_sub$posS1 = NA
data_sub$posS2 = NA

# initialize to 0
data_sub$posL1[1] &amp;lt;- 0; data_sub$posL2[1] &amp;lt;- 0
data_sub$posS1[1] &amp;lt;- 0; data_sub$posS2[1] &amp;lt;- 0

data_sub$posL1[data_sub$longs] &amp;lt;- 1
data_sub$posL2[data_sub$longs] &amp;lt;- -1

data_sub$posS1[data_sub$shorts] &amp;lt;- -1
data_sub$posS2[data_sub$shorts] &amp;lt;- 1

data_sub$posL1[data_sub$longExits] &amp;lt;- 0
data_sub$posL2[data_sub$longExits] &amp;lt;- 0
data_sub$posS1[data_sub$shortExits] &amp;lt;- 0
data_sub$posS2[data_sub$shortExits] &amp;lt;- 0

#positions
data_sub$posL1 &amp;lt;- zoo::na.locf(data_sub$posL1); data_sub$posL2 &amp;lt;- zoo::na.locf(data_sub$posL2)
data_sub$posS1 &amp;lt;- zoo::na.locf(data_sub$posS1); data_sub$posS2 &amp;lt;- zoo::na.locf(data_sub$posS2)
data_sub$position1 &amp;lt;- data_sub$posL1 + data_sub$posS1
data_sub$position2 &amp;lt;- data_sub$posL2 + data_sub$posS2

#Returns
data_sub$dailyret1 &amp;lt;- ROC(data_sub$Close) #  last row is [385,] -0.0122636689 -0.0140365802
data_sub$dailyret2 &amp;lt;- ROC(data_sub$Close.1) #  last row is [385,] -0.0122636689 -0.0140365802

#Backshifting here. But signal is for following day returns!. So can still use latest Z-score
data_sub$date = as.Date(row.names(data_sub))
data_sub = xts(data_sub[,-which(names(data_sub) == &amp;quot;date&amp;quot;)], order.by = data_sub[, which(names(data_sub) == &amp;quot;date&amp;quot;)])

#Doesn&amp;#39;t account for number of shares!!!!!
data_sub$pnl = lag(data_sub$position1, 1) * data_sub$dailyret1  + lag(data_sub$position2, 1) * data_sub$dailyret2

#Performance analytics
tryCatch({
  # charts_perf = charts.PerformanceSummary(data_sub$pnl)
  charts.PerformanceSummary(data_sub$pnl)
}, error = function(e){})

dd = table.Drawdowns(data_sub$pnl)
ds_risk = table.DownsideRisk(data_sub$pnl)
ret = table.AnnualizedReturns(data_sub$pnl)


df_ret = list(data_sub = data_sub,
              dd = dd,
              ds_risk = ds_risk,
              ret = ret
              )

return(df_ret)

}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Parameters to be includded in function
stock1 = &amp;quot;SPY&amp;quot;
stock2 = &amp;quot;BRK-B&amp;quot;

start_date = &amp;quot;2000-07-01&amp;quot;
end_date = &amp;quot;2019-12-30&amp;quot;

prop_res = 0.25     #Proportion of results to show
bband_days = 200   #Bollinger band of ratio

#Storing result to function
res = lf_bollinger_pair_trading(stock1, stock2, start_date, end_date, prop_res, bband_days)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;getSymbols&amp;#39; currently uses auto.assign=TRUE by default, but will
## use auto.assign=FALSE in 0.5-0. You will still be able to use
## &amp;#39;loadSymbols&amp;#39; to automatically load data. getOption(&amp;quot;getSymbols.env&amp;quot;)
## and getOption(&amp;quot;getSymbols.auto.assign&amp;quot;) will still be checked for
## alternate defaults.
## 
## This message is shown once per session and may be disabled by setting 
## options(&amp;quot;getSymbols.warning4.0&amp;quot;=FALSE). See ?getSymbols for details.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## WARNING: There have been significant changes to Yahoo Finance data.
## Please see the Warning section of &amp;#39;?getSymbols.yahoo&amp;#39; for details.
## 
## This message is shown once per session and may be disabled by setting
## options(&amp;quot;getSymbols.yahoo.warning&amp;quot;=FALSE).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/jironghuang.github.io/post/market_neutral_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/jironghuang.github.io/post/market_neutral_files/figure-html/unnamed-chunk-2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;displaying-of-results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Displaying of results&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Drawdown period&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res$dd&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         From     Trough         To   Depth Length To Trough Recovery
## 1 2015-08-10 2015-12-10 2017-01-23 -0.0793    367        87      280
## 2 2018-12-13 2018-12-31 2019-01-08 -0.0612     17        12        5
## 3 2018-05-25 2018-07-17 2018-08-06 -0.0543     50        36       14
## 4 2017-01-24 2017-03-09 2018-01-26 -0.0520    255        32      223
## 5 2018-02-26 2018-02-27 2018-04-11 -0.0343     32         2       30&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Downside risk&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res$ds_risk&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                   pnl
## Semi Deviation                 0.0030
## Gain Deviation                 0.0050
## Loss Deviation                 0.0041
## Downside Deviation (MAR=210%)  0.0092
## Downside Deviation (Rf=0%)     0.0029
## Downside Deviation (0%)        0.0029
## Maximum Drawdown               0.0793
## Historical VaR (95%)          -0.0066
## Historical ES (95%)           -0.0106
## Modified VaR (95%)            -0.0039
## Modified ES (95%)             -0.0039&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Returns&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res$ret&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                              pnl
## Annualized Return         0.0473
## Annualized Std Dev        0.0717
## Annualized Sharpe (Rf=0%) 0.6601&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Prototype Pair Trading Strategy for Silver ETFs</title>
      <link>/jironghuang.github.io/post/prototype-of-pair-trading-strategy-for-silver-etfs/</link>
      <pubDate>Tue, 18 Dec 2018 13:03:44 +0800</pubDate>
      
      <guid>/jironghuang.github.io/post/prototype-of-pair-trading-strategy-for-silver-etfs/</guid>
      <description>&lt;p&gt;In these 2 weeks, I&amp;rsquo;ll deploy my pair trading algo strategy into my server.&lt;/p&gt;

&lt;p&gt;I modified the code below from a renowned quant trader, Ernest Chan. The basic idea is to find z-scores through moving average &amp;amp; moving SD of spread. If it&amp;rsquo;s more than absolute of z-score, I will either short or long the spread depending on the polarity.&lt;/p&gt;

&lt;p&gt;In the backtesting below (using a pair of silver ETFs as an example), I assumed a hypothetical amount of 10,000 dollars per trade.&lt;/p&gt;

&lt;p&gt;Results are pretty good with a healthy sharpe ratio of 2.7 in the training set and 1.6 in the testing set of data. Annualized return is approximately 26% (translates to 2600 dollars) for the test set.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/jironghuang.github.io/post/img/equity_curve.png&#34; alt=&#34;/post/img/equity_curve.png&#34;&gt;
&lt;img src=&#34;/jironghuang.github.io/post/img/summary_stats.png&#34; alt=&#34;/post/img/summary_stats.png&#34;&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rm(list=ls()) # clear workspace

library(&#39;zoo&#39;)
library(&amp;quot;tidyr&amp;quot;)
library(&amp;quot;dplyr&amp;quot;)
require(&amp;quot;quantmod&amp;quot;)
require(&amp;quot;urca&amp;quot;)
require(&amp;quot;PerformanceAnalytics&amp;quot;)
source(&#39;R/util/calculateReturns.R&#39;)
source(&#39;R/util/calculateMaxDD.R&#39;)
source(&#39;R/util/backshift.R&#39;)
source(&#39;R/util/extract_stock_prices.R&#39;)

#List of silver etfs, SIVR, USV, SLV, DBS
stock1 = &amp;quot;SIVR&amp;quot;
stock2 = &amp;quot;USV&amp;quot;

start_date = &amp;quot;2014-12-30&amp;quot;
end_date = &amp;quot;2018-12-30&amp;quot;

prop_train = 0.65
enter_z_score = 2     #Can use nlmb to vary
exit_z_score = 1     #Can use nlmb to vary

trade_amount = 10000
finance_rates = 2.5/100

data1 = df_crawl_time_series(stock1, start_date, end_date)
data1 = subset(data1, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Close&amp;quot;))
data1$Date = as.Date(data1$Date)

data2 = df_crawl_time_series(stock2, start_date, end_date)
data2 = subset(data2, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Close&amp;quot;))
data2$Date = as.Date(data2$Date)

data1 = xts(data1[, -1], order.by = data1[, 1])
data2 = xts(data2[, -1], order.by = data2[, 1])

data = merge(data1, data2)
data = as.data.frame(data)
data = subset(data, !is.na(data$Close) &amp;amp; !is.na(data$Close.1))

#  define indices for training and test sets
trainset &amp;lt;- 1:as.integer(nrow(data) * prop_train)
testset &amp;lt;- (length(trainset)+1):nrow(data)

#Cointegration test--&amp;gt;See if test of r&amp;lt;=1 &amp;gt; threshold. If more cointegrating
jotest=ca.jo(data.frame(data$Close[trainset], data$Close.1[trainset]), type=&amp;quot;trace&amp;quot;, K=2, ecdet=&amp;quot;none&amp;quot;, spec=&amp;quot;longrun&amp;quot;)
summary(jotest)

is_coint = jotest@teststat[1] &amp;gt; jotest@cval[1,3]
if(is_coint){
  print(&amp;quot;This pair&#39;s training set is cointegrating&amp;quot;)
}else{
  print(&amp;quot;This pair&#39;s training set is not cointegrating&amp;quot;)  
}

#Hedge ratio
result &amp;lt;- lm(data$Close[trainset] ~ 0 + data$Close.1[trainset])
hedgeRatio &amp;lt;- coef(result) # 1.631

#Spread
data$spread &amp;lt;- data$Close - hedgeRatio * data$Close.1

##########################Calculate half life#############################
# Calculate half life of mean reversion (residuals)
# Calculate yt-1 and (yt-1-yt)
# pull residuals to a vector
spread_train = data$spread[trainset]
y.lag &amp;lt;- c(spread_train[2:length(spread_train)], 0) # Set vector to lag -1 day
y.lag &amp;lt;- y.lag[1:length(y.lag)-1] # As shifted vector by -1, remove anomalous element at end of vector
spread_train &amp;lt;- spread_train[1:length(spread_train)-1] # Make vector same length as vector y.lag
y.diff &amp;lt;- spread_train - y.lag # Subtract todays close from yesterdays close
y.diff &amp;lt;- y.diff [1:length(y.diff)-1] # Make vector same length as vector y.lag
prev.y.mean &amp;lt;- y.lag - mean(y.lag, na.rm = T) # Subtract yesterdays close from the mean of lagged differences
prev.y.mean &amp;lt;- prev.y.mean [1:length(prev.y.mean )-1] # Make vector same length as vector y.lag
final.df &amp;lt;- data.frame(y.diff,prev.y.mean) # Create final data frame

# Linear Regression With Intercept
result &amp;lt;- lm(y.diff ~ prev.y.mean, data = final.df)
half_life &amp;lt;- -log(2)/coef(result)[2]   #Looking at this to 

if(half_life &amp;lt; 3){
  half_life = 14
}

######################MA of Spread#################################
#Change this to half life for lookback--&amp;gt;https://flare9xblog.com/2017/11/02/pairs-trading-testing-for-conintergration-adf-johansen-test-half-life-of-mean-reversion/
#Try EMA too
data$spread = zoo::na.locf(data$spread)
data$spreadMean &amp;lt;- SMA(data$spread, round(half_life))
data$spreadStd &amp;lt;- runSD(data$spread, n = round(half_life), sample = TRUE, cumulative = FALSE)

# data$spreadMean &amp;lt;- mean(data$spread[trainset], na.rm = T)
# data$spreadStd &amp;lt;- sd(data$spread[trainset], na.rm = T)

data$zscore = (data$spread - data$spreadMean)/data$spreadStd

data$longs &amp;lt;- data$zscore &amp;lt;= -enter_z_score # buy spread when its value drops below 2 standard deviations.
data$shorts &amp;lt;- data$zscore &amp;gt;= enter_z_score # short spread when its value rises above 2 standard deviations.

#  exit any spread position when its value is within 1 standard deviation of its mean.
data$longExits   &amp;lt;- data$zscore &amp;gt;= -exit_z_score 
data$shortExits &amp;lt;- data$zscore &amp;lt;= exit_z_score 

#Signal
data$posL1 = NA
data$posL2 = NA
data$posS1 = NA
data$posS2 = NA

# initialize to 0
data$posL1[1] &amp;lt;- 0; data$posL2[1] &amp;lt;- 0
data$posS1[1] &amp;lt;- 0; data$posS2[1] &amp;lt;- 0

data$posL1[data$longs] &amp;lt;- 1
data$posL2[data$longs] &amp;lt;- -1

data$posS1[data$shorts] &amp;lt;- -1
data$posS2[data$shorts] &amp;lt;- 1

data$posL1[data$longExits] &amp;lt;- 0
data$posL2[data$longExits] &amp;lt;- 0
data$posS1[data$shortExits] &amp;lt;- 0
data$posS2[data$shortExits] &amp;lt;- 0

#positions
data$posL1 &amp;lt;- zoo::na.locf(data$posL1); data$posL2 &amp;lt;- zoo::na.locf(data$posL2)
data$posS1 &amp;lt;- zoo::na.locf(data$posS1); data$posS2 &amp;lt;- zoo::na.locf(data$posS2)
data$position1 &amp;lt;- data$posL1 + data$posS1
# data$position1 = -data$position1    #Don&#39;t know why. It should be flipped!!!

data$position2 &amp;lt;- data$posL2 + data$posS2
# data$position2 = -data$position2    #Don&#39;t know why. It should be flipped!!!

#Returns
data$dailyret1 &amp;lt;- ROC(data$Close) #  last row is [385,] -0.0122636689 -0.0140365802
data$dailyret2 &amp;lt;- ROC(data$Close.1) #  last row is [385,] -0.0122636689 -0.0140365802

#Backshifting here. But signal is for following day returns!. So can still use latest Z-score
data$date = as.Date(row.names(data))
data = xts(data[,-which(names(data) == &amp;quot;date&amp;quot;)], order.by = data[, which(names(data) == &amp;quot;date&amp;quot;)])

data$pnl = lag(data$position1, 1) * data$dailyret1  + lag(data$position2, 1) * data$dailyret2

#Sharpe ratio
sharpeRatioTrainset &amp;lt;- sqrt(252)*mean(data$pnl[trainset], na.rm = TRUE)/sd(data$pnl[trainset], na.rm = TRUE)
sharpeRatioTrainset

sharpeRatioTestset &amp;lt;- sqrt(252)*mean(data$pnl[testset], na.rm = TRUE)/sd(data$pnl[testset], na.rm = TRUE)
sharpeRatioTestset 

#Performance analytics
charts.PerformanceSummary(data$pnl[testset])
table.Drawdowns(data$pnl[testset])
table.DownsideRisk(data$pnl[testset])
table.AnnualizedReturns(data$pnl[testset])

#Number of days not in the market
sum(data$pnl == 0, na.rm = T)/length(data$pnl)

#Putting a trade indicator
data$trade_indicator = lag(ifelse(data$position2 != 0 &amp;amp; !is.na(data$position2), 1, 0))

#Putting a unique id
count = 0
data$trade_id = NA

for(i in 2:nrow(data)){ 
  if(as.numeric(data$trade_indicator[i-1]) == 0 &amp;amp; as.numeric(data$trade_indicator[i]) != 0){
    count = count + 1
    data$trade_id[i] = count
  }else if(as.numeric(data$trade_indicator[i-1]) != 0 &amp;amp; as.numeric(data$trade_indicator[i]) != 0){
    data$trade_id[i] = count
  }
}

#Simple trade statistics
data$test = 0; data$test[testset] = 1 
data$pnl_add1 = data$pnl + 1
data_trade = as.data.frame(data)
data_trade_stats = data_trade %&amp;gt;%
  group_by(trade_id, test) %&amp;gt;%
  summarize(trade_duration = n(),
            cum_pnl = prod(pnl_add1, na.rm = T))

data_trade_stats$cum_pnl = data_trade_stats$cum_pnl - 1
data_trade_stats$profit_per_trade = data_trade_stats$cum_pnl * trade_amount

#Financing charges --&amp;gt;Depends on length of days
data_trade_stats$finance_fees =  trade_amount * finance_rates * (data_trade_stats$trade_duration/365)

#Commission fees
data_trade_stats$comm_fess = 4  #2 for 1 pair

#Net profit
data_trade_stats$profit_per_trade_less_comms = data_trade_stats$profit_per_trade - data_trade_stats$finance_fees - data_trade_stats$comm_fess

#Average loss
data_trade_stats = data_trade_stats[-which(is.na(data_trade_stats)), ]

data_trade_stats %&amp;gt;%
  group_by(test) %&amp;gt;%
  summarize(sum_profits = sum(profit_per_trade_less_comms), 
            mean_profits = mean(profit_per_trade_less_comms),
            na.rm = T)

sum(data_trade_stats$profit_per_trade_less_comms &amp;lt; 0)/ nrow(data_trade_stats)

summary(data_trade_stats$profit_per_trade_less_comms)

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
