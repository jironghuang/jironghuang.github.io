<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>investing on Jirong&#39;s sandbox</title>
    <link>/categories/investing/</link>
    <description>Recent content in investing on Jirong&#39;s sandbox</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Tue, 20 Oct 2020 11:50:49 +0800</lastBuildDate>
    <atom:link href="/categories/investing/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Plans for trend following strategy in futures using continuous forecast</title>
      <link>/post/plans-for-trend-following-strategy-in-futures-using-binary-forecast/</link>
      <pubDate>Tue, 20 Oct 2020 11:50:49 +0800</pubDate>
      
      <guid>/post/plans-for-trend-following-strategy-in-futures-using-binary-forecast/</guid>
      <description>

&lt;h2 id=&#34;trend-following-strategy-in-futures-using-non-binary-forecasts&#34;&gt;Trend following strategy in futures using non binary forecasts&lt;/h2&gt;

&lt;h3 id=&#34;project-motivation&#34;&gt;Project motivation&lt;/h3&gt;

&lt;p&gt;As David Ricardo, a British economist in the 19th century once said, ‘cut short your losses and let your profits trend’ allude to the point that trend following as a profitable strategy could exist even back then.&lt;/p&gt;

&lt;p&gt;Having read AQR’s papers on the Time Series Momentum (TSMOM, I am keen to explore this topic in the futures space (Moskowitz, T. J., Ooi, Y. H., &amp;amp; Pedersen, L. H. (2012)). This strategy has been explored by the Quantopian community and the source code &amp;amp; dataset could be found in this github repository (&lt;a href=&#34;https://github.com/quantopian/research_public/tree/master/advanced_sample_analyses/TSMOM&#34; target=&#34;_blank&#34;&gt;https://github.com/quantopian/research_public/tree/master/advanced_sample_analyses/TSMOM&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Besides AQR papers, I have also followed closely the work of Robert Carver, an ex-MAN AHL quant who specialized in the space of intermediate to long term trend-following futures strategies.&lt;/p&gt;

&lt;h3 id=&#34;dataset&#34;&gt;Dataset&lt;/h3&gt;

&lt;p&gt;Futures dataset across 4 asset classes: Indices, Bonds, Currencies, Commodites&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Quantopian datset up till 2016
Presumably stiched through backward, forward, proportional adjusted methodology&lt;/li&gt;
&lt;li&gt;CHRIS Wiki Continuous Futures dataset in Quandl (&lt;a href=&#34;https://www.quandl.com/data/CHRIS-Wiki-Continuous-Futures&#34; target=&#34;_blank&#34;&gt;https://www.quandl.com/data/CHRIS-Wiki-Continuous-Futures&lt;/a&gt;)
Datasets are stitched with continuous raw non-adjusted prices but not backward, forward, proportional adjusted. There are varaitions of front contract, second contract, third contract, etc.
To use it for data modelling purposes, I would have to assume that rollover is required on certain date (through volume or open interest)&lt;/li&gt;
&lt;li&gt;Steven Analytics Futures dataset in Quandl (&lt;a href=&#34;https://www.quandl.com/databases/SCF/data&#34; target=&#34;_blank&#34;&gt;https://www.quandl.com/databases/SCF/data&lt;/a&gt;)
Stiched datasets with variations of backward, forward, proportional adjustment
Behind paywall&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;data-mining&#34;&gt;Data mining&lt;/h3&gt;

&lt;p&gt;In AQR papers, the authors experimented with fixed lookback periods of 1 year and deciding on the trading signal for the next month i.e. if price of an asset increase over 1 year period, the trading signal for next month would be long. Reverse holds when price of an asset decreased. Position of each asset is based on lookback exponential standard deviation of daily returns with annualized volatility of 40%. Agglomerated to a portfolio, the annualized standard deviation is closer to 12% with approximate sharpe of 1.0 over 30 years.&lt;/p&gt;

&lt;p&gt;What I intend to carry out in this research paper instead is something closer to Robert Carver’s methdology,&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;First, compute 3 types of continuous forecasts based on the following,&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Exponential moving averages (e.g. 8-32, 16-64, 32-138)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Raw forecast: Take the difference between pair of moving averages&lt;/li&gt;
&lt;li&gt;Divide raw forecast by instrument-risk (volatility of instrument in price unit) to get a risk adjusted forecast.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Breakouts&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Raw Forecast, scaled price in range: (Pt – Ravg/med N) / (RmaxN – RminN)&lt;/li&gt;
&lt;li&gt;Divide raw forecast by instrument-risk (volatility of instrument in price unit) to get a risk adjusted forecast.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Carry strategy&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Raw Forecast = (Front contract price – Next contract price)/ distance between contract&lt;/li&gt;
&lt;li&gt;Divide raw forecast by instrument-risk (volatility of instrument in price unit) to get a risk adjusted forecast.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Rescale the signals in point 1 to obtain average absolute signal strength of 10 for each individual forecasts across time. Rescaling factor based on expanding window of median acoss all instruments.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Combine signals in point 2 across systems. Bootstrapping or block bootstrapping with expanding window is used to find the optimal weights (on in-sample or out-of sample data. Requires guidance on this). Cap the signal at -20 to +20.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;With diversification, the combined signal in point 3 will bring down the average signal strength to below 10. A forecast diversification multiplier (FDM) is required to bring the signal to average of 10 again. FDM  = 1/[sqrt(W X H X Wtranspose)], where W is the forecast weights, H is the correlation matrix of forecast values in point 1&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Position allocation is based on lookback exponential volatility of 25 trading days. May look into stratification by asset classes.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;E.g. 25% volatility target on 1,000,000 portfolio would indicate annualized risk of 250,000 with daily risk of 250,000/16 = 15,625&lt;/li&gt;
&lt;li&gt;If there are 4 assets classes, each asset class is allocated 3,906 of daily risk&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If there are 4 instruments in each asset class. This would be approximately 977 dollars daily risk per instrument. Signal of +10 for an instrument would indicate 977 dollars of risk and +20 (strong positve forecasts) would indicate 1954 dollars of risk.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Entry and exit rules are based on continuous forecasts instead of binary entries and exits. i.e. strategy is dependent on the state of the forecasts&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;evaluation-of-strategies&#34;&gt;Evaluation of strategies&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Sharpe/ Sortino ratio&lt;/li&gt;
&lt;li&gt;Calmar ratio/ Max drawdown&lt;/li&gt;
&lt;li&gt;Beta/ Fama-French 3 factor analysis&lt;/li&gt;
&lt;li&gt;Skew/ kurtosis of strategies&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;potential-challenges-and-require-further-deliberation-on-following-pointers&#34;&gt;Potential challenges and require further deliberation on following pointers&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Stitching of futures dataset.&lt;/li&gt;
&lt;li&gt;When and how do we rollover in practice?&lt;/li&gt;
&lt;li&gt;Is it essential to avoid front contracts? To avoid the ‘oil contract’ negative prices issue in early 2020?&lt;/li&gt;
&lt;li&gt;Do we always remain in the contract with highest volume/ open interest?&lt;/li&gt;
&lt;li&gt;How do we find optimal weights in 3.3 in practice&lt;/li&gt;
&lt;li&gt;How do we use boostrapping properly to avoid in-sample bias?&lt;/li&gt;
&lt;li&gt;In optimisation, do we usually optimize based on in-sample data or do we also consider the results in validation dataset? E.g. Sharpe ratio in in-sample data and validation dataset shouldn’t differ by x%. If so, is this difference filtered by the program. And would this run a risk of curve-fitting?&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Hurst, Brian, Yao Hua Ooi, and Lasse Heje Pedersen. &amp;ldquo;A century of evidence on trend-following investing.&amp;ldquo; The Journal of Portfolio Management 44, no. 1 (2017): 15-29.&lt;/li&gt;
&lt;li&gt;Moskowitz, Tobias J., Yao Hua Ooi, and Lasse Heje Pedersen. &amp;ldquo;Time series momentum.&amp;ldquo; Journal of financial economics 104, no. 2 (2012): 228-250.&lt;/li&gt;
&lt;li&gt;Carver, Robert. Systematic Trading: A unique new method for designing trading and investing systems. Harriman House Limited, 2015.&lt;/li&gt;
&lt;li&gt;Carver, Robert.Leveraged Trading. Harriman House Limited, 2019.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Could volatility targeting increase risk-adjusted returns for quantitative strategies</title>
      <link>/post/volatility-targeting-could-potentially-increase-risk-adjusted-returns-for-any-quant-strategies/</link>
      <pubDate>Wed, 29 Jul 2020 11:50:49 +0800</pubDate>
      
      <guid>/post/volatility-targeting-could-potentially-increase-risk-adjusted-returns-for-any-quant-strategies/</guid>
      <description>

&lt;h2 id=&#34;volatility-targeting-could-potentially-increase-risk-adjusted-returns-for-quantitative-strategies&#34;&gt;Volatility targeting could potentially increase risk-adjusted returns for quantitative strategies&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Note: Man AHL&amp;rsquo;s framework in this &lt;a href=&#34;https://www.man.com/maninstitute/volatility-is-back-better-to-target-returns-or-target-risk&#34;&gt;paper&lt;/a&gt; is used in the write-up here.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s say you researched and managed to find a quantitative strategy that suits your risk-reward preferences. How do you further improve your strategy while managing your risk?&lt;/p&gt;

&lt;p&gt;A common way in the trend-following and risk parity space is to target risk - also known as volatility targeting.&lt;/p&gt;

&lt;p&gt;In this article, I will present some simulations to bring you through my thought process on how I apply volatility targeting to my strategies.&lt;/p&gt;

&lt;p&gt;My simulations in this article showed that by applying volatility targeting, I could potentially increase my risk-adjusted returns by 10% (risk adjusted metric sharpe ratio increase from 1.62 to 1.79).&lt;/p&gt;

&lt;h3 id=&#34;what-is-volatility-targeting&#34;&gt;What is volatility targeting?&lt;/h3&gt;

&lt;p&gt;Volatility targeted funds are usually pegged to annualized volatility/ standard deviation. To provide some context, I will provide some intuition on how annualized standard deviation is derived.&lt;/p&gt;

&lt;p&gt;Assuming variance of daily portfolio returns are independent (ignore serial correlation of returns), you could sum up variance of returns across days as follows,&lt;/p&gt;

&lt;p&gt;Variance of portfolio returns across a year (252 trading days) = Var(ret1): Variance of return on day 1 + &amp;hellip;. + Var(ret252): Variance of return on day 252.&lt;/p&gt;

&lt;p&gt;If the variance of daily returns are the same, you could multiply variance of daily returns by 252 to obtain annualized variance of portfolio returns, Annual Variance = 252 * Var(ret)&lt;/p&gt;

&lt;p&gt;To normalize it to annual standard deviation, you&amp;rsquo;ve to take a square root of Annual Variance.&lt;/p&gt;

&lt;p&gt;How do you interpret this metric? Let&amp;rsquo;s say a strategy has an expected returns of 8% with annual standard deviation of 10%. Based on naive normality assumptions, there&amp;rsquo;s a 68% chance that the fund&amp;rsquo;s annualized return will be between -2% to 18%; and 95% chance that the fund&amp;rsquo;s returns will be between -12% to 28%.&lt;/p&gt;

&lt;p&gt;There are couple of ways for fund managers to derive the volatilities,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;One way is to simply find the standard deviation of returns over last X days and annualize it.&lt;/li&gt;
&lt;li&gt;A second way is to find the exponentially weighted standard deviation. See here (&lt;a href=&#34;https://financetrain.com/calculate-historical-volatility-using-ewma/&#34; target=&#34;_blank&#34;&gt;https://financetrain.com/calculate-historical-volatility-using-ewma/&lt;/a&gt;) for further explanation. In my simulations below, I&amp;rsquo;m using this variation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;are-we-leaving-chips-on-the-table-can-we-afford-more-risk-when-should-we-take-chips-off-the-table&#34;&gt;Are we leaving chips on the table? Can we afford more risk? When should we take chips off the table?&lt;/h3&gt;

&lt;p&gt;Below, I simulate a non volatility-targeted risk-parity portfolio rebalanced monthly i.e. portfolio is allocated across different asset classes based on risk rather than dollar value. Within asset classes, tickers are also risk-weighted. See here (&lt;a href=&#34;https://en.wikipedia.org/wiki/Risk_parity&#34; target=&#34;_blank&#34;&gt;https://en.wikipedia.org/wiki/Risk_parity&lt;/a&gt;) for further explanation.&lt;/p&gt;

&lt;p&gt;Rolling standard deviation of raw portfolio is plotted below to illustrate the portfolio risk across time. From the diagram below, you would notice that there are periods where the portfolio risk is significantly below the 10% volatility target. Are there chips left on the table? Could you afford more risk?&lt;/p&gt;

&lt;p&gt;There are periods where portfolio risk is significantly above the 10% volatility target. Case in point during Covid sell-off? Should you be reducing risk instead?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/volatility curve.png&#34; alt=&#34;/post/img/volatility curve.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;Equity curves and portfolio statistics are included below for benchmarking purposes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/raw_portfolio.png&#34; alt=&#34;/post/img/raw_portfolio.png&#34;&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Portfolio&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Annualized returns&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Volatility&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Sharpe&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Max Drawdown&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Return/Max Drawdown&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Skewness&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Benchmark&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8.97%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.5%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.62&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-7.96%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.14&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;what-if-we-target-risk-i-e-undertake-more-risk-during-calm-periods-and-less-risk-during-turbulent-periods&#34;&gt;What if we target risk? i.e. undertake more risk during calm periods and less risk during turbulent periods?&lt;/h3&gt;

&lt;p&gt;So does taking more risk during calm periods and reducing risk during turbulent periods pay off?&lt;/p&gt;

&lt;p&gt;Before, we proceed further, here are some assumptions I included in the simulations,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Portfolio is rebalanced monthly at the start of the trading day.&lt;/li&gt;
&lt;li&gt;On a daily basis, the algorithm checks for the current standard deviation of portfolio based on lookback period of 36 days. If it&amp;rsquo;s lesser than 10%, it will leverage proportionately (to a cap of 1.6 times). If it&amp;rsquo;s more than 10%, leverage will be reduced.&lt;/li&gt;
&lt;li&gt;Leverage financing costs and commission fees are included.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Based on the equity curve and portfolio statistics below, the answer to the question posed earlier in the section is a resounding YES! It&amp;rsquo;s risk-reducing and returns enhancing to target volatility. Risk adjusted returns (Sharpe ratio) increased by 10% (1.62 to 1.79) and Return/ Max Drawdown is considerably higher. You would also notice that the negative skewness of the strategy improved considerably from -1.14 to -0.8.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/curve_lev.png&#34; alt=&#34;/post/img/curve_lev.png&#34;&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Portfolio&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Annualized returns&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Volatility&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Sharpe&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Max Drawdown&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Return/Max Drawdown&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Skewness&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Benchmark&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8.97%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.5%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.62&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-7.96%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.14&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Vol target (10%, max leverage of 1.6 times)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;13.92%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.4%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.79&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-8.02%&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.73&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;risk-reward-preferences&#34;&gt;Risk-reward preferences&lt;/h3&gt;

&lt;p&gt;Above example is all but a single scenario. You could carry out a grid search to find the appropriate volatility target and leverage possibility space.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve included the possibility space with respect to annualized returns, sharpe ratio, max drawdown to understand the risk-reward preferences.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/Returns.png&#34; alt=&#34;/post/img/Returns.png&#34;&gt;
&lt;img src=&#34;/post/img/sharpe.png&#34; alt=&#34;/post/img/sharpe.png&#34;&gt;
&lt;img src=&#34;/post/img/drawdown.png&#34; alt=&#34;/post/img/drawdown.png&#34;&gt;
&lt;img src=&#34;/post/img/skewness.png&#34; alt=&#34;/post/img/skewness.png&#34;&gt;
&lt;img src=&#34;/post/img/kurtosis.png&#34; alt=&#34;/post/img/kurtosis.png&#34;&gt;&lt;/p&gt;

&lt;h3 id=&#34;caveat&#34;&gt;Caveat&lt;/h3&gt;

&lt;p&gt;Note: Above portfolio is currently in incubation prior to deployment.&lt;/p&gt;

&lt;h3 id=&#34;full-tear-sheet-of-10-volatility-target-and-max-leverage-of-1-6-included-for-reference&#34;&gt;Full tear sheet of 10% volatility target and Max leverage of 1.6 included for reference&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/tear_sheet.png&#34; alt=&#34;/post/img/tear_sheet.png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Framework for capital allocation</title>
      <link>/post/framework-for-capital-allocation/</link>
      <pubDate>Thu, 16 Jul 2020 11:50:49 +0800</pubDate>
      
      <guid>/post/framework-for-capital-allocation/</guid>
      <description>

&lt;h2 id=&#34;framework-for-capital-allocation&#34;&gt;Framework for capital allocation&lt;/h2&gt;

&lt;p&gt;In this resource starved world, capital is scarce. Every dollar that you own has its place and deserves to be allocated properly.&lt;/p&gt;

&lt;p&gt;Currently, I already have a huge chunk of capital tied up in a diversified portfolio levered up to 1.4 times. Portfolio has (&amp;amp; expected to) outperformed/ matched up to market returns with 2 to 3 times lower risk - in terms of standard deviation and drawdown.&lt;/p&gt;

&lt;p&gt;But going forward, if I discover a strategy that exhibits appealing characteristics (e.g reasonably high returns with low or inverse correlation to broad markets, crisis alpha), how do I allocate capital to this strategy without increasing my leverage?&lt;/p&gt;

&lt;p&gt;To answer this question, I developed a framework that I will adopt for each strategy.&lt;/p&gt;

&lt;iframe src=&#34;https://app.lucidchart.com/documents/embeddedchart/75c86678-fec4-49cb-b4f8-568a9412e87e&#34; width=&#34;1200&#34; height=&#34;1200&#34; style=&#34;border: none;&#34;&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Integrating volatility targeting into Jarvis, my expert advisor</title>
      <link>/post/volatility-targeting/</link>
      <pubDate>Sun, 15 Mar 2020 11:50:49 +0800</pubDate>
      
      <guid>/post/volatility-targeting/</guid>
      <description>

&lt;h2 id=&#34;volatility-targeting&#34;&gt;Volatility targeting&lt;/h2&gt;

&lt;p&gt;Currently, I&amp;rsquo;ve a suite of toolkits integrated into my Jarvis that advises me on the investing decisions that I&amp;rsquo;ve to make on a daily basis.&lt;/p&gt;

&lt;p&gt;On the latest feature I cobbled together on a Saturday evening, 2 weeks ago, I&amp;rsquo;ve decided to measure the volatility of my portfolio formally.&lt;/p&gt;

&lt;p&gt;Why I&amp;rsquo;m doing this is because managing risks in the form of volatility is easier than targeting returns.&lt;/p&gt;

&lt;p&gt;On any given day, it&amp;rsquo;s easier to predict volatility than returns itself because of its persistent nature.&lt;/p&gt;

&lt;p&gt;Think of it as a coin flips with Binomal distribution: B ~ (n, p).&lt;/p&gt;

&lt;p&gt;P is the probability for which you expect a positive expected payout.&lt;/p&gt;

&lt;p&gt;And variance of this win-lose distribution is n * p * (1-p). This variance is easier to &amp;lsquo;predict&amp;rsquo; based on your win rates.&lt;/p&gt;

&lt;p&gt;But market is not simply a binomial distribution, it also needs to take into consideration the portfolio size exposed to market risks and sequence of returns (autocorrelation here) at any given day.&lt;/p&gt;

&lt;p&gt;Current distribution of my portfolio win rate is around 65 to 70%. But because of some negative skew in returns, my portfolio is languishing at status quo (0%) since start of the year.&lt;/p&gt;

&lt;p&gt;Though my portfolio have outperformed the indexes by a factor of 2 to 3, the steep drawdown during March period of my portfolio could have been prevented if I&amp;rsquo;ve put a hedge early on (if I&amp;rsquo;ve done it through a systematic quant way) to maintain a fixed volatility target.&lt;/p&gt;

&lt;p&gt;Hence, I decided to integrate the volatility targeting feature into Jarvis that advises me daily on the amount of index hedge to place to maintain my portfolio at a constant volatility target; not a perfect way to maintain volatility target (since my portfolio is not perfectly correlated to index) but I find it cumbersome and potentially costly to sell off multiple counters on a daily basis. I used a global etf as a proxy to maintain my risk level since my portfolio has a global tilt.&lt;/p&gt;

&lt;p&gt;Here is the volatility of my levered portfolio. Notice how it spiked up 5 times in the month of March this year.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/vol_target.png&#34; alt=&#34;/post/img/vol_target.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;What volatility targeting does is to supposedly to turn the volatility curve into a straight line.&lt;/p&gt;

&lt;p&gt;You may find the code below. I won&amp;rsquo;t delve into the details but this is essentially what it does,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Obtain my current positions from googlesheet&lt;/li&gt;
&lt;li&gt;Compute my portfolio value converted into SGD now and historically based on current positions&lt;/li&gt;
&lt;li&gt;Compute annual standard deviation (normal and exponential version shared by Robert Carver) of my portfolio based on past 36 days daily returns. Annual non exponential standard deviation returns of portfolio = Daily standard deviation of returns of portfolio * sqrt(252)&lt;/li&gt;
&lt;li&gt;Compute benchmark (VT) volatility&lt;/li&gt;
&lt;li&gt;Compute &amp;lsquo;imperfect&amp;rsquo; hedge required to achieve volatility target of 15%&lt;/li&gt;
&lt;li&gt;Pushes a notification to me on how much additional/ lesser hedge is required&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#Note: Volatility targeting

#Initialization
sapply(c(&amp;quot;ggplot2&amp;quot;, &amp;quot;plotly&amp;quot;, &amp;quot;quantmod&amp;quot;, &amp;quot;pushoverr&amp;quot;, &amp;quot;zoo&amp;quot;, &amp;quot;dplyr&amp;quot;, &amp;quot;roll&amp;quot;, &amp;quot;PerformanceAnalytics&amp;quot;, &amp;quot;pushoverr&amp;quot;, &amp;quot;googlesheets&amp;quot;, &amp;quot;pracma&amp;quot;, &amp;quot;timeDate&amp;quot;, &amp;quot;riingo&amp;quot;), require, character.only = T)
source(&#39;util/extract_stock_prices.R&#39;)

rsd_file = Sys.getenv(&amp;quot;GOOGLESHEET&amp;quot;)
gs_auth(token = rsd_file)
suppressMessages(gs_auth(token = rsd_file, verbose = FALSE))

dat = gs_title(&amp;quot;Investment&amp;quot;)
gs_ws_ls(dat)   #tab names
data &amp;lt;- gs_read(ss=dat, ws = &amp;quot;debt_to_equity&amp;quot;, skip=0)
leverage = 1 + data$Ratio[3]
# leverage = 1
current_hedge_value = data$Ratio[nrow(data)]

currency = &amp;quot;SGD=X&amp;quot;
last_date = Sys.Date() - 200
benchmark = &amp;quot;VT&amp;quot;
num_counters = 24

##########################Obtain portfolio info##########################
# df_tickers = data.frame(tickers = c(&amp;quot;TLT&amp;quot;, &amp;quot;IEF&amp;quot;, &amp;quot;SPY&amp;quot;, ))
df_tickers &amp;lt;- gs_read(ss=dat, ws = &amp;quot;investment_live&amp;quot;, skip=0)
# df_tickers = subset(df_tickers, df_tickers$Ticker != &amp;quot;CNYB.AS&amp;quot;)
df_tickers = filter(df_tickers, num_units &amp;gt; 0)

current_value = sum(df_tickers$value)

df_tickers = df_tickers[, 1:5]
df_tickers[which(df_tickers$exch_rate_type == &amp;quot;SGDHKD=X&amp;quot;), 5] = &amp;quot;HKDSGD=X&amp;quot;

##########################Format data function##########################
#Create a time series of data, then merge in. Just filter out weekend only
data_format = function(ticker, num_units, currency, last_date){

  #Create date range
  create_date = function(i){
    return(last_date + i)
  }
  
  df = data.frame(Date = sapply(0:(Sys.Date() - last_date), create_date))
  df$Date = as.Date(df$Date, origin = &amp;quot;1970-01-1&amp;quot;)
  df$isWeekend = isWeekend(df$Date)
  df$Date = as.character(df$Date)
  
  #Read data
  data_temp = df_crawl_time_series(ticker, &amp;quot;1970-07-01&amp;quot;, &amp;quot;2030-12-30&amp;quot;)
  data_temp = subset(data_temp, data_temp$Date &amp;gt;= last_date &amp;amp; data_temp$Date &amp;lt;= Sys.Date())
  data = merge(df, data_temp, by = c(&amp;quot;Date&amp;quot;), all.x = T)

  #Fill NAs
  data = subset(data, data$isWeekend == F)
  
  if(is.na(data$Adj.Close[1])){
    data$Adj.Close[1] = data$Adj.Close[2]
  }

  if(is.na(data$Adj.Close[1])){
    data$Adj.Close[1] = data$Adj.Close[3]
  }
  
  if(is.na(data$Adj.Close[1])){
    data$Adj.Close[1] = data$Adj.Close[4]
  }
  
    
  data$Adj.Close = na.locf(data$Adj.Close)
  
  #Subset out data-frame
  df = data.frame(Date = data$Date, Price = data$Adj.Close, stringsAsFactors = F)
  
  #Read in num_units
  df$num_units = num_units
  
  #Subset date range
  df = subset(df, df$Date &amp;gt;= last_date &amp;amp; df$Date &amp;lt;= Sys.Date())
  
  #Read in currency
  currency = df_crawl_time_series(currency, &amp;quot;1970-07-01&amp;quot;, &amp;quot;2030-12-30&amp;quot;)
  currency$Adj.Close = na.locf(currency$Adj.Close)
  currency = subset(currency, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Adj.Close&amp;quot;))
  
  #Merge in currency
  df = df %&amp;gt;%
    left_join(., currency, by = c(&amp;quot;Date&amp;quot;))
  
  #Convert to local currency
  df$local_unit_value = df$Price * df$Adj.Close
  df$local_value = df$local_unit_value * df$num_units
  
  #Return date, portfolio value     
  df$Date = as.Date(df$Date)
  
  #ticker
  df$ticker = ticker
  
  df_sub = subset(df, df$Date &amp;gt;= last_date &amp;amp; df$Date &amp;lt;= Sys.Date())
    
  return(df_sub)    
}

########################Formatting portfolio function####################
portfolio_format = function(df_tickers, last_date){

i = 1
ticker_agg = data_format(df_tickers$Ticker[i], df_tickers$num_units[i], df_tickers$exch_rate_type[i], last_date)  

for(i in 2:nrow(df_tickers)){
  print(i)
  ticker_ind = data_format(df_tickers$Ticker[i], df_tickers$num_units[i], df_tickers$exch_rate_type[i], last_date)  
  ticker_agg = rbind(ticker_agg, ticker_ind)
}

portfolio = ticker_agg %&amp;gt;%
  group_by(Date) %&amp;gt;%
  summarize(portfolio_value = sum(local_value, na.rm = T),
            num_counters = n()
  )

portfolio$portfolio_value_adj = ifelse(portfolio$num_counters &amp;lt; num_counters, NA, portfolio$portfolio_value)

portfolio$upper_sd = mean(portfolio$portfolio_value_adj, na.rm = T) + 0.4 * sd(portfolio$portfolio_value_adj, na.rm = T)
portfolio$lower_sd = mean(portfolio$portfolio_value_adj, na.rm = T) - 0.4 * sd(portfolio$portfolio_value_adj, na.rm = T)
portfolio$portfolio_value_adj2 = ifelse((portfolio$portfolio_value_adj  &amp;gt; portfolio$upper_sd) | (portfolio$portfolio_value_adj  &amp;lt; portfolio$lower_sd),
                                        NA,
                                        portfolio$portfolio_value_adj)
portfolio$portfolio_value_adj2 = na.locf(portfolio$portfolio_value_adj2)

if(!is.na(current_value)){
  portfolio$portfolio_value_adj2[nrow(portfolio)] = current_value
}

portfolio$returns = ROC(portfolio$portfolio_value_adj2) * leverage
portfolio$returns_100 = portfolio$returns * 100

portfolio$roll_std = roll_sd(portfolio$returns, 36)
portfolio$roll_std_annual = portfolio$roll_std * (252 ^ 0.5)

df = portfolio

return(df)

}

##########################Find beta of portfolio######################################
#Find out how much of local_unit_value needed
find_beta = function(df, benchmark){
  
  price_bench = data_format(benchmark, num_units = 10, currency, last_date)
  price_bench$returns = ROC(price_bench$local_value)
  price_bench = subset(price_bench, select = c(&amp;quot;Date&amp;quot;, &amp;quot;returns&amp;quot;, &amp;quot;local_unit_value&amp;quot;))    
  names(price_bench)[2] = &amp;quot;returns_benchmark&amp;quot;

  df_agg = df %&amp;gt;%
    left_join(., price_bench, by = &amp;quot;Date&amp;quot;)
  
  reg = lm(df_agg$returns ~ df_agg$returns_benchmark)
  return(as.numeric(reg$coefficients[2]))
  
}

##########################Pure vol targeting######################################
#Find out how much of local_unit_value needed
#Account for leveraged %

find_vol_units = function(df, benchmark, leverage){
  
  price_bench = data_format(benchmark, num_units=10, currency, last_date)
  price_bench$returns = ROC(price_bench$local_value)
  price_bench = subset(price_bench, select = c(&amp;quot;Date&amp;quot;, &amp;quot;returns&amp;quot;, &amp;quot;local_unit_value&amp;quot;))    
  names(price_bench)[2] = &amp;quot;returns_benchmark&amp;quot;

  df_agg = df %&amp;gt;%
              left_join(., price_bench, by = &amp;quot;Date&amp;quot;)
  
  #Compute EMA of VT price. Loop number of units. And iteratively compute new portfolio value and EMA of SD. Find out closest number of VT units required.
  df_agg$square_returns_target = df_agg$returns_benchmark ^ 2
  df_agg$square_returns_target[1] = df_agg$square_returns_target[2]
  df_agg$ema_vol_target =  movavg(df_agg$square_returns_target, 36, type = &amp;quot;e&amp;quot;)
  df_agg$ema_sd_target = df_agg$ema_vol_target ^ 0.5 * (252 ^ 0.5)
  
  df_agg$square_returns = (df_agg$returns) ^ 2
  df_agg$square_returns[1] = df_agg$square_returns[2]
  df_agg$ema_vol =  movavg(df_agg$square_returns, 36, type = &amp;quot;e&amp;quot;)
  df_agg$ema_sd = df_agg$ema_vol ^ 0.5 * (252 ^ 0.5)
  
  
  return(df_agg)
}

##########################Generate df######################################
df = portfolio_format(df_tickers, last_date)
beta = find_beta(df, benchmark)
df = find_vol_units(df, benchmark, leverage)
reduce_times_exp = df$ema_sd[nrow(df) - 0]/ 0.15

##########################Find hedge required to target risk######################################
hedge = (df$portfolio_value_adj2[nrow(df)] - (df$portfolio_value_adj2[nrow(df)]/ reduce_times_exp)) * (df$ema_sd[nrow(df)] / df$ema_sd_target[nrow(df)])
hedge = round(hedge, 0)

##########################Pushing notifications to inform how much hedge is required######################################
msg = paste0(&amp;quot;You should hedge &amp;quot;, hedge, 
             &amp;quot; Current hedge value is &amp;quot;, current_hedge_value,
             &amp;quot; Additional hedge required &amp;quot;, (hedge - current_hedge_value),
             &amp;quot; Portfolio vol is &amp;quot;, round(df$ema_sd[nrow(df)], 3),
             &amp;quot; Benchmark vol is &amp;quot;, round(df$ema_sd_target[nrow(df)], 3)
)

print(msg)
plot(df$ema_sd)

if(abs(hedge - current_hedge_value) &amp;gt; 3000){
  pushover(message = msg, 
           user = Sys.getenv(&amp;quot;pushover_user&amp;quot;), app = Sys.getenv(&amp;quot;pushover_app&amp;quot;))
  
}

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
