<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>programming on Jirong&#39;s sandbox</title>
    <link>/tags/programming/</link>
    <description>Recent content in programming on Jirong&#39;s sandbox</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Tue, 22 Sep 2020 11:50:49 +0800</lastBuildDate>
    
	<atom:link href="/tags/programming/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Crawling data from basketball-reference and espn</title>
      <link>/post/crawling-data-from-basektball-reference-and-espn/</link>
      <pubDate>Tue, 22 Sep 2020 11:50:49 +0800</pubDate>
      
      <guid>/post/crawling-data-from-basektball-reference-and-espn/</guid>
      <description> Crawling data from basketball-reference and espn As I required some data for my ML assignment, I thought that predicting NBA player salaries based on previous seasons&amp;rsquo; game stats would be cool.
Here&amp;rsquo;re the codes used for crawling the data from basektball-reference and espn.
Codes </description>
    </item>
    
    <item>
      <title>Designing, Building and Deploying a Fully Automated Algorithmic Trading System</title>
      <link>/post/designing-and-deploying-a-fully-automated-algorithmic-trading-system/</link>
      <pubDate>Mon, 24 Aug 2020 11:50:49 +0800</pubDate>
      
      <guid>/post/designing-and-deploying-a-fully-automated-algorithmic-trading-system/</guid>
      <description>Designing, Building and Deploying a Fully Automated Algorithmic Trading System As I developed several inter-day trading/ portfolio management algorithms, I also embarked on a journey in parallel to develop a fully automated execution framework that could satisfy my requirements.
Previously orders were executed manually after signals are generated automatically.
Requirements  A relatively slow trading system triggered by an hourly task scheduler during trading hours. I’m using Linux cron jobs for this.</description>
    </item>
    
    <item>
      <title>Could volatility targeting increase risk-adjusted returns for quantitative strategies</title>
      <link>/post/volatility-targeting-could-potentially-increase-risk-adjusted-returns-for-any-quant-strategies/</link>
      <pubDate>Wed, 29 Jul 2020 11:50:49 +0800</pubDate>
      
      <guid>/post/volatility-targeting-could-potentially-increase-risk-adjusted-returns-for-any-quant-strategies/</guid>
      <description>Volatility targeting could potentially increase risk-adjusted returns for quantitative strategies Note: Man AHL&amp;rsquo;s framework in this paper is used in the write-up here.
Let&amp;rsquo;s say you researched and managed to find a quantitative strategy that suits your risk-reward preferences. How do you further improve your strategy while managing your risk?
A common way in the trend-following and risk parity space is to target risk - also known as volatility targeting.</description>
    </item>
    
    <item>
      <title>Integrating volatility targeting into Jarvis, my expert advisor</title>
      <link>/post/volatility-targeting/</link>
      <pubDate>Sun, 15 Mar 2020 11:50:49 +0800</pubDate>
      
      <guid>/post/volatility-targeting/</guid>
      <description>Volatility targeting Currently, I&amp;rsquo;ve a suite of toolkits integrated into my Jarvis that advises me on the investing decisions that I&amp;rsquo;ve to make on a daily basis.
On the latest feature I cobbled together on a Saturday evening, 2 weeks ago, I&amp;rsquo;ve decided to measure the volatility of my portfolio formally.
Why I&amp;rsquo;m doing this is because managing risks in the form of volatility is easier than targeting returns.</description>
    </item>
    
    <item>
      <title>Mapreduce using Java</title>
      <link>/post/mapreduce-in-java/</link>
      <pubDate>Sun, 15 Mar 2020 11:50:49 +0800</pubDate>
      
      <guid>/post/mapreduce-in-java/</guid>
      <description>Mapreduce using java I haven&amp;rsquo;t coded in java in eons. The assignment (Mapreduce, Pig and Spark) I worked on over last 3 weeks is a good way to jolt me out from my comfort zone.
Java is something I need to brush up on before taking the Software Development Process module which requires me to write an android app. Argh!
Back to Mapreduce. It&amp;rsquo;s a useful framework if you&amp;rsquo;ve to summarise huge datasets (gigabytes, terabytes).</description>
    </item>
    
    <item>
      <title>Regime detection through hidden markov model</title>
      <link>/post/hidden_markov_model/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/hidden_markov_model/</guid>
      <description>Regime detection through hidden markov model It’s rumoured that in the early days of Renaissance Technologies - according to the book ‘The Man Who Solved the Market’ - hidden markov models are used for regime detection.
Here I am, a couple of decades later - employing this strategy. This will be integrated into my ‘Jarvis’ - a series of Algorithmic toolkits that advises me in all situations.
Hidden markov mode is a statistical unsupervised learning model used to model states.</description>
    </item>
    
    <item>
      <title>Regime detection through hidden markov model</title>
      <link>/project/hidden_markov_model/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/project/hidden_markov_model/</guid>
      <description>Regime detection through hidden markov model It’s rumoured that in the early days of Renaissance Technologies - according to the book ‘The Man Who Solved the Market’ - hidden markov models are used for regime detection.
Here I am, a couple of decades later - employing this strategy. This will be integrated into my ‘Jarvis’ - a series of Algorithmic toolkits that advises me in all situations.
Hidden markov mode is a statistical unsupervised learning model used to model states.</description>
    </item>
    
    <item>
      <title>Embedding D3 interactive charts part 2</title>
      <link>/post/embedding-d3-interactive-charts-part2/</link>
      <pubDate>Sun, 23 Feb 2020 11:50:49 +0800</pubDate>
      
      <guid>/post/embedding-d3-interactive-charts-part2/</guid>
      <description>Embedding D3 interactive charts Part 2 - Testing reading in of file from directory Just having fun - testing to see if I could embed D3 charts in my blog.
Seems like it works too! But I would have to upload the csv under public folder first.
   // set the dimensions and margins of the graph var margin = {top: 10, right: 30, bottom: 30, left: 60}, width = 460 - margin.</description>
    </item>
    
    <item>
      <title>Embedding D3 interactive charts</title>
      <link>/post/embedding-d3-interactive-charts/</link>
      <pubDate>Sun, 23 Feb 2020 11:46:40 +0800</pubDate>
      
      <guid>/post/embedding-d3-interactive-charts/</guid>
      <description>Embedding D3 interactive charts Just having fun - testing to see if I could embed D3 charts in my blog.
Seems like it works!
   // set the dimensions and margins of the graph var margin = {top: 10, right: 30, bottom: 30, left: 60}, width = 460 - margin.left - margin.right, height = 450 - margin.top - margin.bottom; // append the svg object to the body of the page var svg = d3.</description>
    </item>
    
    <item>
      <title>Fuzzy matching with many to many matches without loops</title>
      <link>/post/fuzzy_matching_no_loops/</link>
      <pubDate>Fri, 17 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/fuzzy_matching_no_loops/</guid>
      <description>Fuzzy matching As a computer scientist graduate, I always strive to reduce my computational complexity through parallelization or vectorization!
Explicit loops in data science is the root of evil!
For loops &amp;amp; while loops have their places but definitely not in data science space (fairly broad statement here).
In this post here, I hope to show a really cool example that avoids the dreaded O(n square) complexity.
I will be using fuzzy matching to find the closet match of strings in data-frame 2, df2 against data-frame 1, df1.</description>
    </item>
    
    <item>
      <title>Latest lessons learnt from crawling</title>
      <link>/post/crawling-insights/</link>
      <pubDate>Sun, 08 Dec 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/crawling-insights/</guid>
      <description>Lessons learnt I just realised that there&amp;rsquo;s a quick way to understand the xpaths&amp;rsquo; patterns.
In the past, usually what I did is to manually eyeball to infer the patterns from the page source or inspect page.
Silly me!
1 quick way to understand the pattern is through the following,
 Right click on an element in a web page that you are interested in and click on &amp;lsquo;inspect&amp;rsquo; Right click on the node and click &amp;lsquo;copy&amp;rsquo; Copy full xpath  And paste to a notepad.</description>
    </item>
    
    <item>
      <title>Asset allocation notification</title>
      <link>/post/asset_allocation_notification/</link>
      <pubDate>Thu, 12 Sep 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/asset_allocation_notification/</guid>
      <description>Asset allocation notification I&amp;rsquo;m in the midst of automating/ guiding my life with algorithms (largely inspired by Ray Dalio) - and 1 of the guidelines that I set is on asset allocation,
 Emerging market and Developed Market should be of the same proportion Bonds + Cash proportion should be equivalent to my age. This can deviate in times of crisis when I want to be more opportunistic.  If it deviates from the portfolio policy statement, it will send me a pushover notification to my phone:)</description>
    </item>
    
    <item>
      <title>ETF watchlist email notification Through Python</title>
      <link>/post/email_notification_python/</link>
      <pubDate>Tue, 10 Sep 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/email_notification_python/</guid>
      <description>Email notification I finally bit the bullet and updated my previously hideous email notification!
You may find the updated email notification template here - alongside with the code.
Feel free to ping me if you are keen to be on the email list too.
~ Jirong
import smtplib, ssl import datetime import pandas as pd from email.mime.text import MIMEText from email.mime.multipart import MIMEMultipart #Format text data = pd.read_csv(&#39;/home/jirong/Desktop/github/ETF_watchlist/Output/yahoo_crawled_data.csv&#39;) data[&#39;Change_fr_52_week_high&#39;] = round(100 * data[&#39;Change_fr_52_week_high&#39;], 1) data = data[[&#39;Name&#39;, &#39;Price&#39;, &#39;Change_fr_52_week_high&#39;]].</description>
    </item>
    
    <item>
      <title>Convert NAs to Obscure Number in Data Frame to Aid in Recoding/ Feature Engineering</title>
      <link>/post/convert_na_num/</link>
      <pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/convert_na_num/</guid>
      <description>Converting NAs to obscure numbers to prevent the data from messing up the recoding. 1 issue that I encounter while I data-munge is that NAs in data seem to mess up my recoding. Here’s a neat swiss army knife utility function I developed recently.
suppressMessages(library(dplyr)) # Converting NA to obscure number to prevent awkward recoding situations that require &amp;amp; !is.na(&amp;lt;variable&amp;gt;) # Doesn&amp;#39;t work for factors #&amp;#39; @title Convert NA to obscure number #&amp;#39; @param dp_dataframe Dataframe in consideration #&amp;#39; @param np_obscure_num Numeric - Obscure number #&amp;#39; @param bp_na_to_num Boolean if TRUE, convert NA to num.</description>
    </item>
    
    <item>
      <title>Loading excel data with correct variable types</title>
      <link>/post/load_data_with_correct_types/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/load_data_with_correct_types/</guid>
      <description>Loading data with data types When reading static files into R or Python, most of the times we are lazy as we load the data with no regard to the data types.
But in mission critical ETL jobs or Data analytics workflow, data types are quintessential and there’s a fine line between life and death. Ok, I’m exaggerating here.
What I’ve written below is a swiss army knife function to read an excel file: 1st tab is data and 2nd tab is the variable types (e.</description>
    </item>
    
    <item>
      <title>Function to describe clusters derived from unsupervised learning</title>
      <link>/post/cluster_descriptive_stats/</link>
      <pubDate>Fri, 24 May 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/cluster_descriptive_stats/</guid>
      <description>Describing unsupervised learning clusters As a data scientist / analyst, besides doing cool modelling stuff, we&amp;rsquo;re often asked to churn out descriptive statistics. Yes, we know. It&amp;rsquo;s part of the process.
I chanced upon this really nifty concept at work to describe the clusters derived from unsupervised learnig. Here&amp;rsquo;s how it goes,
 Say it&amp;rsquo;s a nominal or ordinal variable. First, I find the proportion of the feature across the X clusters Second, I rank this proportion through percentiles across these X values The cluster with the highest percentile will earn its right to be represented by the feature And if it&amp;rsquo;s a scale variable, you may find the mean of the feature for each cluster and repeat the steps.</description>
    </item>
    
    <item>
      <title>Playing with Google Place API</title>
      <link>/post/google_place_api/</link>
      <pubDate>Tue, 14 May 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/google_place_api/</guid>
      <description>Google Place API I was playing around with the API to obtain lat-long for my geo analytics work.
I entered my credit card info but it seems that I&amp;rsquo;m not charged even with 9000+ API calls. Unsure if it&amp;rsquo;s because I&amp;rsquo;ve a 400+ dollars free cloud credit?
Anyway, what I did here was to make API calls and storing the data into my local database.
If you&amp;rsquo;re interested, you may visit this stackoverflow link (https://stackoverflow.</description>
    </item>
    
    <item>
      <title>Some thoughts on Reinforcement Learning - Q Learning</title>
      <link>/post/q_learning/</link>
      <pubDate>Mon, 08 Apr 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/q_learning/</guid>
      <description>Q learning I just completed a Reinforcement Learning assignment - in particular on Q-learning. According to Wikipedia here, it&amp;rsquo;s a model-free Rl algorithm. The goal for the algo is to learn a policy, which tells an agent what action to take under different circumstances.
Here&amp;rsquo;s my confession. What I&amp;rsquo;m doing in this post is to summarise what I&amp;rsquo;ve just learnt so that I may come back to this at any point in future.</description>
    </item>
    
    <item>
      <title>Hosting a Flask App on Heroku</title>
      <link>/post/hosting-a-flask-app-on-heroku/</link>
      <pubDate>Thu, 28 Feb 2019 23:34:32 +0800</pubDate>
      
      <guid>/post/hosting-a-flask-app-on-heroku/</guid>
      <description>Following the steps here &amp;ndash;&amp;gt; https://realpython.com/flask-by-example-part-1-project-setup/
I managed to deploy my python flask app in Heroku.
from flask import Flask app = Flask(__name__) @app.route(&#39;/&#39;) def hello(): return &amp;quot;Hello World!&amp;quot; @app.route(&#39;/&amp;lt;name&amp;gt;&#39;) def hello_name(name): return &amp;quot;Hello {}!&amp;quot;.format(name) if __name__ == &#39;__main__&#39;: app.run()  You may visit the following link &amp;ndash;&amp;gt;https://jirong-stage.herokuapp.com/ &amp;amp; add a suffix to it.
Example https://jirong-stage.herokuapp.com/jirong &amp;amp; this will return Hello jirong!
Possibilites are immense! I can easily create APIs or host dashboard here.</description>
    </item>
    
    <item>
      <title>Sampling With Replacement Through First Principles</title>
      <link>/post/sampling-with-replacement-through-first-principles/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/sampling-with-replacement-through-first-principles/</guid>
      <description>Sampling with replacement Hello! It&amp;rsquo;s me once again attempting to explain things from first principles - a term popularized by Elon Musk.
I will use some psudeo code - on sampling with replacement for weights - to aid my explanation.
Earlier in the week, I attempted to write a simple function from scratch but I gave up after realising that it will take me more than 15 mins! Difficulties lies in the multiple switch statements in defining the intervals.</description>
    </item>
    
    <item>
      <title>Building a decision tree algorithm from scratch</title>
      <link>/post/building-adecision-tree-from-scratch/</link>
      <pubDate>Fri, 15 Feb 2019 13:09:44 +0800</pubDate>
      
      <guid>/post/building-adecision-tree-from-scratch/</guid>
      <description>Building a decision tree from scratch Sometimes to truly understand and internalise an algorithm, it&amp;rsquo;s always useful to build from scratch. Rather than relying on a module or library written by someone else.
I&amp;rsquo;m fortunate to be given the chance to do it in 1 of my assignments for decision trees.
From this exercise, I had to rely on my knowledge on recursion, binary trees (in-order traversal) and object oriented programming.</description>
    </item>
    
    <item>
      <title>Martingale Strategy - Double Down</title>
      <link>/post/martingale-strategy/</link>
      <pubDate>Sat, 26 Jan 2019 11:46:49 +0800</pubDate>
      
      <guid>/post/martingale-strategy/</guid>
      <description>Martingale Strategy In this post, I will simulate a martingale strategy in Roulette&amp;rsquo;s context to highlight the potential risks associated with this strategy.
Double down! That&amp;rsquo;s essentially the essence of it.
Here&amp;rsquo;s a simple explanation of the strategy,
 The croupier spins the ball. If it&amp;rsquo;s red you win the amount you bet, black you lose the same amount If you win, you continue to bet the same amount (same as your 1st bet amount) If you lose, you double your bet amount And if your accumulated winnings hits a certain amount, you stop and leave the casino  So how would the strategy fare?</description>
    </item>
    
    <item>
      <title>How to Create a Python Environment in Ubuntu or any Debian-based system</title>
      <link>/post/how-to-create-a-python-environment-in-ubuntu/</link>
      <pubDate>Wed, 09 Jan 2019 23:39:22 +0800</pubDate>
      
      <guid>/post/how-to-create-a-python-environment-in-ubuntu/</guid>
      <description>Often, certain projects or classes involving python require a set of modules/packages for the code to work.
1 solution is to create a Python Environment dedicated to that project.
First set up a folder, and include a .yml file with the specific modules and environment that you wish to install. Here is an example (env.yml),
name: env channels: !!python/tuple - !!python/unicode &#39;defaults&#39; dependencies: - nb_conda=2.2.0=py27_0 - python=2.7.13=0 - cycler=0.10.0 - functools32=3.</description>
    </item>
    
    <item>
      <title>Translating Ernest Chan Kalman Filter Strategy Matlab and Python Code Into R</title>
      <link>/post/translating-ernest-chan-kalman-filter-strategy-matlab-and-python-code-into-r/</link>
      <pubDate>Tue, 01 Jan 2019 00:15:53 +0800</pubDate>
      
      <guid>/post/translating-ernest-chan-kalman-filter-strategy-matlab-and-python-code-into-r/</guid>
      <description>Translating Ernest Chan Kalman Filter Strategy Matlab and Python Code Into R I&amp;rsquo;m really intrigued by Ernest Chan&amp;rsquo;s approach in Quant Trading.
Often in the retail trading space, what &amp;lsquo;gurus&amp;rsquo; preach often sounds really dubious. But Ernest Chan is different. He&amp;rsquo;s sincere, down-to-earth and earnest (meant to be a pun here).
In my first month of deploying algo trading strategies, I focus mainly on mean-reversion strategies - paricularly amongst pairs.</description>
    </item>
    
    <item>
      <title>Summary of My Computational Photography Module From Georgia Tech Computer Science Masters</title>
      <link>/post/summary-of-my-computational-photography-from-georgia-tech-computer-science-masters/</link>
      <pubDate>Sat, 08 Dec 2018 01:11:52 +0800</pubDate>
      
      <guid>/post/summary-of-my-computational-photography-from-georgia-tech-computer-science-masters/</guid>
      <description>For what&amp;rsquo;s worth, here is a summary of what I went through for my Georgia Tech Computer Science Msc Computational Photography module.
And it&amp;rsquo;s really painful but rewarding!</description>
    </item>
    
    <item>
      <title>Colorization</title>
      <link>/post/colorization/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/colorization/</guid>
      <description>Colorization The following is a high level project pipeline of my Computational Photography Colorization report. The project scope involves minimizing a quadratic cost function. An artist would only need to make a few colour scribble on a grey photograph and the algorithm will automatically populate the entire photograph with the associated colours.
1.Input: I first read in the image using imread function.
2.Find the difference: Next I compute the difference between the marked and grey scale image.</description>
    </item>
    
    <item>
      <title>Architecture and Process Flow for My Algorithmic Trading</title>
      <link>/post/architecture-and-process-flow-for-my-algorithmic-trading/</link>
      <pubDate>Sun, 04 Nov 2018 10:19:13 +0800</pubDate>
      
      <guid>/post/architecture-and-process-flow-for-my-algorithmic-trading/</guid>
      <description> Project that I will be working in 2018-2019 </description>
    </item>
    
    <item>
      <title>Seam Carving</title>
      <link>/post/seam-carving/</link>
      <pubDate>Thu, 25 Oct 2018 13:23:23 +0800</pubDate>
      
      <guid>/post/seam-carving/</guid>
      <description>Snippet of my Seam Carving Report from my Msc Computer Science Georgia Tech&amp;rsquo;s Computational Photography module Besides removing of streams, we can also add streams. We identify k streams for removal and duplicate by averaging the left and right neighbours. The computation of these averages is done by convolving the following matrix with the images’ colour channels.
kernel = np.array([[0, 0, 0], [0.5, 0, 0.5], [0, 0, 0]])  In the implementation of my scaling_up algorithm, I first remove k streams (depending on ratio set by user) and recorded the coordinates and cumulative energy values of the original picture in each removal.</description>
    </item>
    
    <item>
      <title>R package: Decomposing a Position Into Exchange Rate and Non Exchange Rate Effects</title>
      <link>/post/decomposing-a-position-into-exchange-rate-and-non-exchange-rate-effects/</link>
      <pubDate>Thu, 25 Oct 2018 11:39:24 +0800</pubDate>
      
      <guid>/post/decomposing-a-position-into-exchange-rate-and-non-exchange-rate-effects/</guid>
      <description>Decomposing a Position Into Exchange Rate and Non Exchange Rate Effects If you are someone with a stake in foreign positions, this package I wrote here may be a useful tool to help you understand the impact of foreign currency on your positions. For instance,
 If you are an investor, you may use it to analyze impact of exchange rate on your investment positions. If you are in the treasury department, you may wish to analyze the impact of exchange rates on your bonds.</description>
    </item>
    
    <item>
      <title>Shift Share Analysis Package I developed</title>
      <link>/post/shift-share-analysis-package/</link>
      <pubDate>Sat, 22 Sep 2018 12:23:28 +0800</pubDate>
      
      <guid>/post/shift-share-analysis-package/</guid>
      <description>Shift-share Analysis Package I developed During my career, I often have to deal with compositional &amp;amp; within group effects. For instance, the employment rate fell by 3% across 2 period. How much of it is due to an increase in employment rate within the sub-group and how much of it is due to compositional shift (for example ageing population).
A formal way to explain these effects is known as shift-share analysis.</description>
    </item>
    
    <item>
      <title>Automated Email Notification of my ETF watchlist</title>
      <link>/post/automated_email_notification/</link>
      <pubDate>Tue, 04 Sep 2018 01:37:53 +0800</pubDate>
      
      <guid>/post/automated_email_notification/</guid>
      <description>I wrote an automated email notification code to send out my daily ETF watchlist in csv - an extension of my ETF watchlist project here. I figured out that people will not visit my site. So why not blast out the watchlist instead:)
And if you are interested in the code. Here you go.
#Steps for sending watchlist library(&amp;quot;rJava&amp;quot;) library(&#39;mailR&#39;) source(&amp;quot;./R/emails.R&amp;quot;) # Write the content of your email msg &amp;lt;- paste(&amp;quot;Hey there, I&#39;m sending this ETF watchlist that is updated as of &amp;quot;, &amp;quot;\n&amp;quot;, as.</description>
    </item>
    
    <item>
      <title>Naming Conventions in R. Let&#39;s call it JR Notations</title>
      <link>/post/jr-naming-conventions-in-r/</link>
      <pubDate>Sun, 26 Aug 2018 14:09:02 +0800</pubDate>
      
      <guid>/post/jr-naming-conventions-in-r/</guid>
      <description>Naming Conventions in R. Let&amp;rsquo;s call it JR Notations. &amp;lsquo;Naming conventions&amp;rsquo; is a huge thing in many programming languages/ paradigms/ communities. But it&amp;rsquo;s noticeably absent in the R programming community.
With some inspiration from the Hungarian Notation, here&amp;rsquo;s a blue-print that I came up with while working on a major R project over the last 2 months. Drumroll please&amp;hellip;
1. Naming conventions for R scripts  F_ for R scripts that contains functions.</description>
    </item>
    
  </channel>
</rss>